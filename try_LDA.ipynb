{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DocumentSet Class using mutable struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsBase, CSV, DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocumentSet"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct DocumentSet\n",
    "    documents::Array\n",
    "    document_size::Int\n",
    "    vocab_count::Int\n",
    "    vocabulary::Dict{}\n",
    "    reverse_vocabulary::Array\n",
    "end\n",
    "\n",
    "function documentset_readData(path::String, documentset_obj::DocumentSet)\n",
    "    open(path) do file\n",
    "        for doc in eachline(file)\n",
    "            documentset_addDocument(doc, documentset_obj)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function documentset_readData(texts::Array, documentset_obj::DocumentSet)\n",
    "    for doc in texts\n",
    "        documentset_addDocument(doc, documentset_obj)\n",
    "    end\n",
    "end\n",
    "\n",
    "function documentset_addDocument(line::String, documentset_obj::DocumentSet)\n",
    "    if isempty(line)\n",
    "        return nothing\n",
    "    end\n",
    "    words = split(line)\n",
    "    codes = []\n",
    "    for i in words\n",
    "        if haskey(documentset_obj.vocabulary, i)\n",
    "            push!(codes, documentset_obj.vocabulary[i])\n",
    "        else \n",
    "            documentset_obj.vocab_count+=1\n",
    "            documentset_obj.vocabulary[i] = documentset_obj.vocab_count\n",
    "            push!(documentset_obj.reverse_vocabulary, i)\n",
    "            push!(codes, documentset_obj.vocab_count)\n",
    "        end\n",
    "    end\n",
    "    push!(documentset_obj.documents, codes)\n",
    "    documentset_obj.document_size+=1\n",
    "end\n",
    "\n",
    "function documentset_addDocument(words::Array, documentset_obj::DocumentSet)\n",
    "    if isempty(words)\n",
    "        return nothing\n",
    "    end\n",
    "    codes = []\n",
    "    for i in words\n",
    "        if haskey(documentset_obj.vocabulary, i)\n",
    "            push!(codes, documentset_obj.vocabulary[i])\n",
    "        else \n",
    "            documentset_obj.vocab_count+=1\n",
    "            documentset_obj.vocabulary[i] = documentset_obj.vocab_count\n",
    "            push!(documentset_obj.reverse_vocabulary, i)\n",
    "            push!(codes, documentset_obj.vocab_count)\n",
    "        end\n",
    "    end\n",
    "    push!(documentset_obj.documents, codes)\n",
    "    documentset_obj.document_size+=1\n",
    "end\n",
    "\n",
    "function documentset_transform(line::String, documentset_obj::DocumentSet)\n",
    "    words = split(line)\n",
    "    codes = []\n",
    "    for i in words\n",
    "        code = get(documentset_obj.vocabulary, i, -1)\n",
    "        if code != -1\n",
    "            push!(codes, code)\n",
    "        end  \n",
    "    end\n",
    "    return sort(codes)\n",
    "end\n",
    "\n",
    "function documentset_sampleDocuments(numDocs::Int, documentset_obj::DocumentSet)\n",
    "    subD = sample(documentset_obj.documents, numDocs, replace = false)\n",
    "    return subD  \n",
    "end\n",
    "\n",
    "function documentset_OnlinesampleDocuments(numDocs::Int, iter::Int, documentset_obj::DocumentSet)\n",
    "    subD = documentset_obj.documents[(iter-1)*numDocs+1: (iter)*numDocs]\n",
    "    return subD\n",
    "end\n",
    "\n",
    "function documentset_getTermFreq(documentset_obj::DocumentSet)\n",
    "    tf = [0 for i=1:documentset_obj.vocab_count]\n",
    "    for doc in documentset_obj.documents\n",
    "        for w in doc\n",
    "            tf[w]+=1 \n",
    "        end\n",
    "    end\n",
    "    return tf\n",
    "end\n",
    "\n",
    "DocumentSet() = DocumentSet([],0, 0, Dict(), [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class call and using data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global corpus = DocumentSet()\n",
    "documentset_readData(\"dummy.txt\", corpus) #Or use readData(readlines(\"dummy.txt\"), corpus)\n",
    "V = size(corpus.reverse_vocabulary)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra function testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total docs: 5\n"
     ]
    }
   ],
   "source": [
    "println(\"Total docs: $(corpus.document_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"This\", \"is\", \"dummy\", \"line\", \"number\", \"1\", \"2\", \"3\", \"4th\", \"5th\", \"6th\"]\n",
      "[3, 3, 6, 6, 3, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "println(corpus.reverse_vocabulary)\n",
    "println(documentset_getTermFreq(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{Any,1}:\n",
       " Any[1, 2, 3, 4, 5, 6]\n",
       " Any[1, 2, 3, 4, 5, 7]\n",
       " Any[1, 2, 3, 4, 5, 8]\n",
       " Any[9, 3, 4]\n",
       " Any[10, 3, 4]\n",
       " Any[11, 3, 4]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 11 entries:\n",
       "  \"number\" => 5\n",
       "  \"1\"      => 6\n",
       "  \"is\"     => 2\n",
       "  \"2\"      => 7\n",
       "  \"6th\"    => 11\n",
       "  \"dummy\"  => 3\n",
       "  \"5th\"    => 10\n",
       "  \"line\"   => 4\n",
       "  \"This\"   => 1\n",
       "  \"4th\"    => 9\n",
       "  \"3\"      => 8"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Any,1}:\n",
       "  3\n",
       "  4\n",
       " 10"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documentset_transform(\"5th dummy line\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Any,1}:\n",
       " Any[1, 2, 3, 4, 5, 8]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documentset_OnlinesampleDocuments(1,3, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documentset_addDocument(\"6th dummy line\", corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SymmetricDirichlet Class(not extending Dirichlet) using struct\n",
    "Don't need to create this class, we can use Dirichlet Class for such kind of variables as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SymmetricDirichlet"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct SymmetricDirichlet\n",
    "    K::Int16\n",
    "    alpha::Float16\n",
    "    sumAlpha::Float16\n",
    "end\n",
    "\n",
    "SymmetricDirichlet(K, a) = SymmetricDirichlet(K, a, K*a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SymmetricDirichlet(10, Float16(0.01), Float16(0.1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M=100\n",
    "alpha = [0.01 for i in 1:M];\n",
    "wordPrior = SymmetricDirichlet(V,0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirichlet Class using mutable struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dirichlet"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global MINIMUM_PARAM = 10E-200\n",
    "\n",
    "mutable struct Dirichlet\n",
    "    K::Int64\n",
    "    alpha::Array{Float64}\n",
    "    sumAlpha::Float64\n",
    "end\n",
    "\n",
    "function dirichlet_optimizeParam(Ck, ndkMax, C_, ndMax, numIteration, dirichlet_obj::Dirichlet)\n",
    "    function digammaRecurrence(nMax, C, z)\n",
    "        if z==0.0\n",
    "            return 0.0\n",
    "        end\n",
    "        \n",
    "        R=0; S=0;\n",
    "        for n in 1:nMax\n",
    "            R+= 1.0 / (n-1+z)\n",
    "            S+= C[n]*R\n",
    "        end\n",
    "        return S\n",
    "    end\n",
    "            \n",
    "    for i in 1:numIteration\n",
    "        demon = digammaRecurrence(ndMax, C_, dirichlet_obj.sumAlpha)\n",
    "        \n",
    "        for k in 1:dirichlet_obj.K\n",
    "            numer = digammaRecurrence(ndkMax[k], Ck[k], dirichlet_obj.alpha[k])\n",
    "            dirichlet_obj.alpha[k] *= (numer/demon)\n",
    "            dirichlet_obj.alpha[k] = max(dirichlet_obj.alpha[k], MINIMUM_PARAM)\n",
    "        end\n",
    "        dirichlet_obj.sumAlpha = sum(dirichlet_obj.alpha)\n",
    "    end\n",
    "end\n",
    "\n",
    "function dirichlet_set(param, dirichlet_obj::Dirichlet)\n",
    "    for k in 1:dirichlet_obj.K\n",
    "        dirichlet_obj.alpha[k] = param[k] > MINIMUM_PARAM ? param[k] : MINIMUM_PARAM\n",
    "    end\n",
    "end\n",
    "\n",
    "Dirichlet(param::Array) = Dirichlet(size(param)[1], param, sum(param))\n",
    "Dirichlet(K::Int, a::Float64) = Dirichlet(K, [a for i in 1:K], K*a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicPrior = Dirichlet(alpha);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Polya using mutable struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Polya"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct Polya\n",
    "    K::Int64\n",
    "    dir::Dirichlet\n",
    "    n::Array{Int64}\n",
    "    N::Int64\n",
    "end\n",
    "\n",
    "function polya_p(x::Int, polya_obj::Polya)\n",
    "    return (polya_obj.n[x]+polya_obj.dir.alpha[x]) / (polya_obj.N+polya_obj.dir.sumAlpha)\n",
    "end\n",
    "\n",
    "function polya_p(X::Array, polya_obj::Polya)\n",
    "    p = 1.0\n",
    "    for x in X\n",
    "        p*= polya_p(x, polya_obj)\n",
    "        polya_observe(x, polya_obj)\n",
    "    end\n",
    "    for x in X\n",
    "        polya_forget(x, polya_obj)\n",
    "    end\n",
    "    return p\n",
    "end\n",
    "  \n",
    "function polya_observe(x::Int, polya_obj::Polya)\n",
    "    polya_obj.n[x]+=1\n",
    "    polya_obj.N+=1  \n",
    "end\n",
    "\n",
    "function polya_observe(X::Array, polya_obj::Polya)\n",
    "    for x in X\n",
    "        polya_observe(x, polya_obj)\n",
    "    end\n",
    "end\n",
    "\n",
    "function polya_forget(x::Int, polya_obj::Polya)\n",
    "    polya_obj.n[x] -= 1\n",
    "    polya_obj.N -= 1\n",
    "end\n",
    "\n",
    "function polya_forget(X::Array, polya_obj::Polya)\n",
    "    for x in X\n",
    "        polya_forget(x, polya_obj)\n",
    "    end\n",
    "end\n",
    "\n",
    "function polya_getCount(k::Int, polya_obj::Polya)\n",
    "    return polya_obj.n[k]\n",
    "end\n",
    "\n",
    "Polya(param::Dirichlet) = Polya(param.K, param, [0 for i in 1:param.K], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampler_class's sample function is used in LDA class so defining only the function instead of complete class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sampler_sample (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Sampler_sample(p)\n",
    "    u = rand()*sum(p)\n",
    "    for i in 1:size(p)[1]\n",
    "        if u<=p[i]\n",
    "            return i\n",
    "        end\n",
    "        u-=p[i]\n",
    "    end\n",
    "    return size(p)[1]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polya Test Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Polya(3, Dirichlet(3, [3.0, 2.0, 2.0], 7.0), [0, 0, 0], 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = [3.0, 2.0, 2.0]\n",
    "sut = Polya(Dirichlet(param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001082251082251082"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [1,3,3,1,1,2]\n",
    "polya_p(X, sut) # In java test is(closeTo(0.00108225108, 10E-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1 = DocumentSet()\n",
    "documentset_readData(\"news.txt\", corpus1)\n",
    "sut = Polya(Dirichlet(12, 1.0))\n",
    "for doc in corpus1.documents\n",
    "    for x in doc\n",
    "        polya_observe(x, sut)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125\n",
      "0.09375\n",
      "0.0625\n"
     ]
    }
   ],
   "source": [
    "println(polya_p(1, sut)) # in java is(0.125)\n",
    "println(polya_p(5, sut)) # in java is(0.09375)\n",
    "println(polya_p(8, sut)) # in java is(0.0625)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class LDA using mutable struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LDA"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct LDA\n",
    "    numIteration::Int64\n",
    "    M::Int64\n",
    "    topicDir::Dirichlet\n",
    "    wordPolya::Array{Polya}\n",
    "    X::Array{Any,1}\n",
    "    topicPolya::Array{Polya}\n",
    "end\n",
    "\n",
    "function lda_sample(docs, lda_obj::LDA)\n",
    "    lda_obj.X = docs\n",
    "    D = size(docs)[1]\n",
    "    #lda_obj.topicPolya =  Polya[D]   not sure how can i make it happen, doing it with iterations, working fine\n",
    "    ndMax = Int(floor(maximum([size(doc)[1] for doc in docs])))\n",
    "    \n",
    "    C_ = [0 for i in 1:ndMax+1]\n",
    "    for d in 1:D\n",
    "        C_[(size(docs[d])[1])+1]+=1 # In julia indexing start from 1 so adding 1 in every index to compensate 0 size docs\n",
    "    end\n",
    "    \n",
    "    samples = [[] for i=1:D]\n",
    "    for d in 1:D\n",
    "        Nd = size(docs[d])[1]\n",
    "        \n",
    "        samples[d] = [0 for i in 1:Nd]\n",
    "        push!(lda_obj.topicPolya, Polya(lda_obj.topicDir))\n",
    "        \n",
    "        temp = []\n",
    "        #randomSamples = sample(1:lda_obj.M, Nd, replace=false)\n",
    "        for i in 1:Nd\n",
    "            randomSample = rand(1:lda_obj.M)\n",
    "            push!(temp, randomSample)\n",
    "            lda_addSample(d, i, randomSample, lda_obj)\n",
    "        end\n",
    "        samples[d] = temp\n",
    "    end\n",
    "    \n",
    "    for iteration in 1:lda_obj.numIteration\n",
    "        for d in 1:D\n",
    "            Nd = size(docs[d])[1]\n",
    "            for i in 1:Nd\n",
    "                lda_removeSample(d, i, samples[d][i], lda_obj)\n",
    "                samples[d][i] = Sampler_sample(lda_posterior(d, i, lda_obj))\n",
    "                lda_addSample(d, i, samples[d][i], lda_obj)\n",
    "            end\n",
    "        end\n",
    "     \n",
    "        ndkMax = [0 for i in 1:lda_obj.M]\n",
    "        Ck = [[0 for j in 1:ndMax+1] for i in 1:lda_obj.M]\n",
    "        for m in 1:lda_obj.M\n",
    "            for d in 1:D\n",
    "                ndk = lda_obj.topicPolya[d].n[m]\n",
    "                Ck[m][ndk+1]+=1\n",
    "                ndkMax[m] = max(ndkMax[m], ndk)\n",
    "            end\n",
    "        end\n",
    "        dirichlet_optimizeParam(Ck, ndkMax, C_, ndMax+1, 20, lda_obj.topicDir)\n",
    "    end\n",
    "    return samples\n",
    "end\n",
    "\n",
    "function lda_posterior(d::Int, i::Int, lda_obj::LDA)\n",
    "    v = lda_obj.X[d][i]\n",
    "    posterior = [0.0 for i in 1:lda_obj.M]\n",
    "    for m in 1:lda_obj.M\n",
    "        posterior[m] = polya_p(m, lda_obj.topicPolya[d]) * polya_p(v, lda_obj.wordPolya[m])\n",
    "    end\n",
    "    return posterior\n",
    "end\n",
    "\n",
    "function lda_addSample(d::Int, i::Int, m::Int, lda_obj::LDA)\n",
    "    v = lda_obj.X[d][i]\n",
    "    polya_observe(m, lda_obj.topicPolya[d])\n",
    "    polya_observe(v, lda_obj.wordPolya[m])\n",
    "end\n",
    "\n",
    "function lda_removeSample(d::Int, i::Int, m::Int, lda_obj::LDA)\n",
    "    v = lda_obj.X[d][i]\n",
    "    polya_forget(m, lda_obj.topicPolya[d])\n",
    "    polya_forget(v, lda_obj.wordPolya[m])\n",
    "end\n",
    "\n",
    "function lda_wordPredict(m::Int, v::Int, lda_obj::LDA)\n",
    "    return polya_p(v, lda_obj.wordPolya[m])\n",
    "end\n",
    "\n",
    "function lda_topicPredict(d::Int, m::Int, lda_obj::LDA)\n",
    "    return polya_p(m, lda_obj.topicPolya[d])\n",
    "end\n",
    "\n",
    "LDA(topicPrior::Dirichlet, wordPrior::Dirichlet) = LDA(100, topicPrior.K, topicPrior, [Polya(wordPrior) for i in 1:topicPrior.K], [[]], [])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First compelte test starts from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = DocumentSet()\n",
    "documentset_readData(\"news.txt\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordPrior = Dirichlet(12, 0.01)\n",
    "M = 3\n",
    "alpha = [0.01 for i in 1:M];\n",
    "topicPrior = Dirichlet(alpha);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(topicPrior, wordPrior);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Array{Any,1},1}:\n",
       " [1, 1, 1, 1]\n",
       " [2, 2, 1, 2]\n",
       " [3, 1, 1, 3]\n",
       " [1, 3, 2, 2]\n",
       " [1, 3, 2, 3]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = lda_sample(corpus.documents, lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t ロシア \t 0.3300438596491228\n",
      "1 \t モスクワ \t 0.11074561403508773\n",
      "1 \t 戦車 \t 0.22039473684210525\n",
      "1 \t 部隊 \t 0.22039473684210525\n",
      "1 \t 五輪 \t 0.0010964912280701756\n",
      "1 \t メダル \t 0.0010964912280701756\n",
      "1 \t 自衛隊 \t 0.0010964912280701756\n",
      "1 \t 国防 \t 0.0010964912280701756\n",
      "1 \t マラソン \t 0.11074561403508773\n",
      "1 \t 選手 \t 0.0010964912280701756\n",
      "1 \t 時代 \t 0.0010964912280701756\n",
      "1 \t 文化 \t 0.0010964912280701756\n",
      "2 \t ロシア \t 0.0016339869281045752\n",
      "2 \t モスクワ \t 0.32843137254901955\n",
      "2 \t 戦車 \t 0.0016339869281045752\n",
      "2 \t 部隊 \t 0.0016339869281045752\n",
      "2 \t 五輪 \t 0.32843137254901955\n",
      "2 \t メダル \t 0.32843137254901955\n",
      "2 \t 自衛隊 \t 0.0016339869281045752\n",
      "2 \t 国防 \t 0.0016339869281045752\n",
      "2 \t マラソン \t 0.0016339869281045752\n",
      "2 \t 選手 \t 0.0016339869281045752\n",
      "2 \t 時代 \t 0.0016339869281045752\n",
      "2 \t 文化 \t 0.0016339869281045752\n",
      "3 \t ロシア \t 0.001953125\n",
      "3 \t モスクワ \t 0.001953125\n",
      "3 \t 戦車 \t 0.001953125\n",
      "3 \t 部隊 \t 0.001953125\n",
      "3 \t 五輪 \t 0.001953125\n",
      "3 \t メダル \t 0.001953125\n",
      "3 \t 自衛隊 \t 0.197265625\n",
      "3 \t 国防 \t 0.197265625\n",
      "3 \t マラソン \t 0.001953125\n",
      "3 \t 選手 \t 0.197265625\n",
      "3 \t 時代 \t 0.197265625\n",
      "3 \t 文化 \t 0.197265625\n"
     ]
    }
   ],
   "source": [
    "for m in 1:3\n",
    "    for v in 1:12\n",
    "        word = corpus.reverse_vocabulary[v]\n",
    "        val = lda_wordPredict(m, v, lda)\n",
    "        println(\"$m \\t $word \\t $val\" )\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t 1 \t 0.20038549687894103\n",
      "1 \t 2 \t 0.3700239077010383\n",
      "1 \t 3 \t 0.1181801937565314\n",
      "1 \t 4 \t 0.3114104016634894\n",
      "2 \t 1 \t 0.20038549687894103\n",
      "2 \t 2 \t 0.14652320457795337\n",
      "2 \t 3 \t 0.1181801937565314\n",
      "2 \t 4 \t 0.5349111047865743\n",
      "3 \t 1 \t 0.08863514531739855\n",
      "3 \t 2 \t 0.5935246108241233\n",
      "3 \t 3 \t 0.1181801937565314\n",
      "3 \t 4 \t 0.1996600501019469\n",
      "4 \t 1 \t 0.08863514531739855\n",
      "4 \t 2 \t 0.14652320457795337\n",
      "4 \t 3 \t 0.1181801937565314\n",
      "4 \t 4 \t 0.6466614563481168\n",
      "5 \t 1 \t 0.08863514531739855\n",
      "5 \t 2 \t 0.14652320457795337\n",
      "5 \t 3 \t 0.4534312484411588\n",
      "5 \t 4 \t 0.3114104016634894\n"
     ]
    }
   ],
   "source": [
    "for d in 1:5\n",
    "    for m in 1:4\n",
    "        val = lda_topicPredict(d, m, lda)\n",
    "        println(\"$d \\t $m \\t $val\" )\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t alpha \t 1.0e-199\n",
      "2 \t alpha \t 1.0485513456954876\n",
      "3 \t alpha \t 1.0e-199\n",
      "4 \t alpha \t 1.0e-199\n",
      "5 \t alpha \t 1.0e-199\n",
      "6 \t alpha \t 1.0e-199\n",
      "7 \t alpha \t 1.0e-199\n",
      "8 \t alpha \t 1.0e-199\n",
      "9 \t alpha \t 1.0e-199\n",
      "10 \t alpha \t 1.0e-199\n",
      "11 \t alpha \t 1.0e-199\n",
      "12 \t alpha \t 1.0e-199\n",
      "13 \t alpha \t 1.0e-199\n",
      "14 \t alpha \t 1.0e-199\n",
      "15 \t alpha \t 1.0e-199\n",
      "16 \t alpha \t 1.0e-199\n",
      "17 \t alpha \t 1.0e-199\n",
      "18 \t alpha \t 1.0e-199\n",
      "19 \t alpha \t 1.0e-199\n",
      "20 \t alpha \t 1.0e-199\n",
      "21 \t alpha \t 1.0e-199\n",
      "22 \t alpha \t 1.0e-199\n",
      "23 \t alpha \t 1.0e-199\n",
      "24 \t alpha \t 1.0e-199\n",
      "25 \t alpha \t 1.0e-199\n",
      "26 \t alpha \t 1.0e-199\n",
      "27 \t alpha \t 1.0e-199\n",
      "28 \t alpha \t 1.0e-199\n",
      "29 \t alpha \t 1.0e-199\n",
      "30 \t alpha \t 1.0e-199\n",
      "31 \t alpha \t 1.0e-199\n",
      "32 \t alpha \t 1.0e-199\n",
      "33 \t alpha \t 1.0e-199\n",
      "34 \t alpha \t 1.0e-199\n",
      "35 \t alpha \t 1.0e-199\n",
      "36 \t alpha \t 1.0e-199\n",
      "37 \t alpha \t 1.0e-199\n",
      "38 \t alpha \t 1.0e-199\n",
      "39 \t alpha \t 1.0e-199\n",
      "40 \t alpha \t 1.0e-199\n",
      "41 \t alpha \t 1.0e-199\n",
      "42 \t alpha \t 1.0e-199\n",
      "43 \t alpha \t 1.0e-199\n",
      "44 \t alpha \t 1.0e-199\n",
      "45 \t alpha \t 1.137249541668945\n",
      "46 \t alpha \t 1.0e-199\n",
      "47 \t alpha \t 1.0e-199\n",
      "48 \t alpha \t 1.0e-199\n",
      "49 \t alpha \t 1.0e-199\n",
      "50 \t alpha \t 1.0e-199\n",
      "51 \t alpha \t 1.0e-199\n",
      "52 \t alpha \t 1.0e-199\n",
      "53 \t alpha \t 1.0e-199\n",
      "54 \t alpha \t 1.0e-199\n",
      "55 \t alpha \t 1.0e-199\n",
      "56 \t alpha \t 1.0e-199\n",
      "57 \t alpha \t 1.0e-199\n",
      "58 \t alpha \t 1.0e-199\n",
      "59 \t alpha \t 1.0e-199\n",
      "60 \t alpha \t 1.0e-199\n",
      "61 \t alpha \t 1.0e-199\n",
      "62 \t alpha \t 1.0e-199\n",
      "63 \t alpha \t 1.0e-199\n",
      "64 \t alpha \t 1.0e-199\n",
      "65 \t alpha \t 1.0e-199\n",
      "66 \t alpha \t 1.0e-199\n",
      "67 \t alpha \t 1.0e-199\n",
      "68 \t alpha \t 1.0e-199\n",
      "69 \t alpha \t 1.0e-199\n",
      "70 \t alpha \t 1.0e-199\n",
      "71 \t alpha \t 1.0e-199\n",
      "72 \t alpha \t 1.0e-199\n",
      "73 \t alpha \t 1.0e-199\n",
      "74 \t alpha \t 1.0e-199\n",
      "75 \t alpha \t 1.0e-199\n",
      "76 \t alpha \t 1.0e-199\n",
      "77 \t alpha \t 1.0e-199\n",
      "78 \t alpha \t 1.0e-199\n",
      "79 \t alpha \t 1.985741678170296\n",
      "80 \t alpha \t 1.0e-199\n",
      "81 \t alpha \t 1.0e-199\n",
      "82 \t alpha \t 1.0e-199\n",
      "83 \t alpha \t 1.0e-199\n",
      "84 \t alpha \t 1.0e-199\n",
      "85 \t alpha \t 1.0e-199\n",
      "86 \t alpha \t 1.0e-199\n",
      "87 \t alpha \t 1.0e-199\n",
      "88 \t alpha \t 1.0e-199\n",
      "89 \t alpha \t 1.0e-199\n",
      "90 \t alpha \t 1.0e-199\n",
      "91 \t alpha \t 1.0e-199\n",
      "92 \t alpha \t 1.0e-199\n",
      "93 \t alpha \t 1.0e-199\n",
      "94 \t alpha \t 1.0e-199\n",
      "95 \t alpha \t 1.0e-199\n",
      "96 \t alpha \t 1.0e-199\n",
      "97 \t alpha \t 1.0e-199\n",
      "98 \t alpha \t 1.0e-199\n",
      "99 \t alpha \t 1.0e-199\n",
      "100 \t alpha \t 1.0e-199\n"
     ]
    }
   ],
   "source": [
    "for m in 1:M\n",
    "    val = topicPrior.alpha[m]\n",
    "    println(\"$m \\t alpha \\t $val\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual topic modeling on NIPS papers dataset(used in fragmentation project as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = CSV.read(\"papers.csv\", DataFrame);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_txt = papers.paper_text;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "specialchars = ['!', '”', '#', '$', '%', '&', '’', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '>', '=', '@', '?', '[', ']', '^', '_', '{', '}', '|', '~']\n",
    "open(\"stopwords.txt\") do file\n",
    "        for word in eachline(file)\n",
    "            push!(stopwords, word)\n",
    "        end\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "remove_stop_words (generic function with 1 method)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function remove_stop_words(docs::Array, stopwords::Array)\n",
    "    new_docs = []\n",
    "    for line in docs\n",
    "        doc = split(line)\n",
    "        temp = []\n",
    "        for word in doc\n",
    "            if !(word in stopwords) \n",
    "                word = replace.(word, specialchars => \"\")\n",
    "                if length(word) > 2 && tryparse(Float64, word) == nothing\n",
    "                    push!(temp, lowercase(word))\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        push!(new_docs, temp)\n",
    "    end\n",
    "    return new_docs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_paper_txt = remove_stop_words(papers_txt, stopwords);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocumentSet(Any[], 0, 0, Dict{Any,Any}(), Any[])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = DocumentSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentset_readData(new_paper_txt, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399426"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.vocab_count #Previous implementation value 478255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordPrior = Dirichlet(corpus.vocab_count, 0.01)\n",
    "M = 30\n",
    "alpha = [0.01 for i in 1:M];\n",
    "topicPrior = Dirichlet(alpha);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(topicPrior, wordPrior);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = lda_sample(corpus.documents, lda);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = [];\n",
    "for m in 1:1\n",
    "    for v in 1:size(corpus.reverse_vocabulary)[1]\n",
    "        val = lda_wordPredict(m, v, lda)\n",
    "        push!(val1, val)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399426,)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Int64,1}:\n",
       "  136\n",
       " 1988\n",
       "  172\n",
       " 1995\n",
       "   25\n",
       " 2077\n",
       " 8085\n",
       " 2995\n",
       " 1825\n",
       "  355"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words = sortperm(val1, rev=true)[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem\n",
      "optimization\n",
      "solution\n",
      "regression\n",
      "the\n",
      "regularization\n",
      "convex\n",
      "sparse\n",
      "constraints\n",
      "min\n"
     ]
    }
   ],
   "source": [
    "for i in top_words\n",
    "    println(corpus.reverse_vocabulary[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 : Any[\"problem\", \"optimization\", \"solution\", \"regression\", \"the\", \"regularization\", \"convex\", \"sparse\", \"constraints\", \"min\"]\n",
      "Topic 2 : Any[\"tree\", \"node\", \"nodes\", \"trees\", \"game\", \"the\", \"search\", \"strategy\", \"games\", \"cost\"]\n",
      "Topic 3 : Any[\"time\", \"state\", \"the\", \"dynamics\", \"process\", \"learning\", \"rate\", \"system\", \"one\", \"point\"]\n",
      "Topic 4 : Any[\"network\", \"networks\", \"the\", \"learning\", \"input\", \"training\", \"neural\", \"units\", \"output\", \"hidden\"]\n",
      "Topic 5 : Any[\"model\", \"latent\", \"data\", \"topic\", \"models\", \"the\", \"number\", \"process\", \"dirichlet\", \"topics\"]\n",
      "Topic 6 : Any[\"matrix\", \"algorithm\", \"matrices\", \"sparse\", \"the\", \"rank\", \"tensor\", \"data\", \"norm\", \"subspace\"]\n",
      "Topic 7 : Any[\"data\", \"the\", \"number\", \"time\", \"using\", \"performance\", \"method\", \"algorithm\", \"set\", \"accuracy\"]\n",
      "Topic 8 : Any[\"gradient\", \"algorithm\", \"optimization\", \"convergence\", \"algorithms\", \"stochastic\", \"methods\", \"method\", \"descent\", \"convex\"]\n",
      "Topic 9 : Any[\"graph\", \"set\", \"nodes\", \"graphs\", \"algorithm\", \"edges\", \"the\", \"function\", \"edge\", \"node\"]\n",
      "Topic 10 : Any[\"neurons\", \"the\", \"neuron\", \"neural\", \"model\", \"spike\", \"activity\", \"cells\", \"stimulus\", \"input\"]\n",
      "Topic 11 : Any[\"the\", \"linear\", \"function\", \"vector\", \"case\", \"error\", \"this\", \"one\", \"matrix\", \"given\"]\n",
      "Topic 12 : Any[\"the\", \"system\", \"memory\", \"network\", \"neural\", \"input\", \"figure\", \"output\", \"circuit\", \"analog\"]\n",
      "Topic 13 : Any[\"the\", \"space\", \"local\", \"data\", \"basis\", \"figure\", \"linear\", \"natural\", \"using\", \"manifold\"]\n",
      "Topic 14 : Any[\"word\", \"words\", \"language\", \"the\", \"model\", \"models\", \"set\", \"text\", \"example\", \"one\"]\n",
      "Topic 15 : Any[\"image\", \"images\", \"object\", \"the\", \"features\", \"objects\", \"model\", \"recognition\", \"feature\", \"visual\"]\n",
      "Topic 16 : Any[\"learning\", \"control\", \"target\", \"the\", \"task\", \"model\", \"tasks\", \"system\", \"trajectory\", \"figure\"]\n",
      "Topic 17 : Any[\"model\", \"ranking\", \"the\", \"user\", \"data\", \"information\", \"items\", \"query\", \"users\", \"item\"]\n",
      "Topic 18 : Any[\"the\", \"model\", \"speech\", \"time\", \"state\", \"sequence\", \"data\", \"models\", \"using\", \"sequences\"]\n",
      "Topic 19 : Any[\"theorem\", \"probability\", \"distribution\", \"let\", \"sample\", \"the\", \"bound\", \"random\", \"log\", \"estimator\"]\n",
      "Topic 20 : Any[\"algorithm\", \"regret\", \"the\", \"online\", \"bound\", \"learning\", \"algorithms\", \"problem\", \"setting\", \"set\"]\n",
      "Topic 21 : Any[\"kernel\", \"kernels\", \"data\", \"test\", \"the\", \"space\", \"causal\", \"using\", \"methods\", \"feature\"]\n",
      "Topic 22 : Any[\"function\", \"loss\", \"functions\", \"learning\", \"the\", \"risk\", \"convex\", \"bound\", \"set\", \"error\"]\n",
      "Topic 23 : Any[\"neural\", \"deep\", \"networks\", \"network\", \"learning\", \"training\", \"layer\", \"model\", \"layers\", \"convolutional\"]\n",
      "Topic 24 : Any[\"model\", \"the\", \"human\", \"figure\", \"two\", \"subjects\", \"brain\", \"models\", \"data\", \"one\"]\n",
      "Topic 25 : Any[\"clustering\", \"data\", \"points\", \"distance\", \"cluster\", \"algorithm\", \"the\", \"clusters\", \"metric\", \"point\"]\n",
      "Topic 26 : Any[\"model\", \"distribution\", \"data\", \"gaussian\", \"models\", \"the\", \"bayesian\", \"posterior\", \"prior\", \"likelihood\"]\n",
      "Topic 27 : Any[\"policy\", \"state\", \"learning\", \"action\", \"the\", \"reward\", \"function\", \"value\", \"actions\", \"reinforcement\"]\n",
      "Topic 28 : Any[\"learning\", \"training\", \"classification\", \"data\", \"features\", \"feature\", \"set\", \"classifier\", \"label\", \"class\"]\n",
      "Topic 29 : Any[\"price\", \"revenue\", \"prices\", \"patients\", \"rst\", \"auctions\", \"patient\", \"risk\", \"buyer\", \"dened\"]\n",
      "Topic 30 : Any[\"variables\", \"inference\", \"models\", \"the\", \"algorithm\", \"graphical\", \"markov\", \"variable\", \"model\", \"belief\"]\n"
     ]
    }
   ],
   "source": [
    "for m in 1:M\n",
    "    val1 = []\n",
    "    for v in 1:size(corpus.reverse_vocabulary)[1]\n",
    "        val = lda_wordPredict(m, v, lda)\n",
    "        push!(val1, val)\n",
    "    end\n",
    "    top_words = sortperm(val1, rev=true)[1:10]\n",
    "    wrds = []\n",
    "    for i in top_words\n",
    "        push!(wrds, corpus.reverse_vocabulary[i])\n",
    "    end\n",
    "    println(\"Topic $m : $wrds\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
