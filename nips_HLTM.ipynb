{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Activating\u001b[22m\u001b[39m environment at `~/Documents/Study/Git_Personal/julia_bayes/TopicModels/Project.toml`\n",
      "┌ Info: Precompiling TopicModels [cfcb1801-bb54-4f1b-8249-336c042d2c46]\n",
      "└ @ Base loading.jl:1278\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "using Distances\n",
    "using StatsBase\n",
    "using DataStructures\n",
    "using ProgressMeter\n",
    "using JSON\n",
    "Pkg.activate(\"TopicModels\")\n",
    "import TopicModels\n",
    "using PyCall\n",
    "using PyPlot\n",
    "\n",
    "using LSHFunctions, LinearAlgebra, BenchmarkTools\n",
    "#corpora = pyimport(\"gensim.corpora\")\n",
    "#ch = pyimport(\"gensim.models.coherencemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <module 'torch' from '/Users/khan/.julia/conda/3/lib/python3.8/site-packages/torch/__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nn = pyimport(\"torch.nn\")\n",
    "np = pyimport(\"numpy\")\n",
    "torch = pyimport(\"torch\")\n",
    "#plt = pyimport(\"matplotlib.pyplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Run on Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus = TopicModels.readData(\"news-en.txt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "wordPrior = TopicModels.Dirichlet(12, 0.01)\n",
    "M = 3\n",
    "alpha = [0.01 for i in 1:M];\n",
    "topicPrior = TopicModels.Dirichlet(alpha);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lda = TopicModels.LDA(topicPrior, wordPrior);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples = TopicModels.lda_sample(corpus.documents, lda);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1st topic and top 5 words along with vocab proportion\n",
    "words, proportions = TopicModels.lda_topicN(3, 4, corpus, lda);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"medal\", \"runner\", \"era\", \"culture\"]\n",
      "[0.39258, 0.19727, 0.19727, 0.19727]\n"
     ]
    }
   ],
   "source": [
    "println(words)\n",
    "println(proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Human in the Loop Topic Modeling with APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, no_lemma_docs = TopicModels.preprocess(\"nips/papers_refined.csv\", 1000); #took 1:35 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load lda object from saved json\n",
    "#lda = TopicModels.loadLDA(\"nips/lda_obj.json\"); #only takes few seconds \n",
    "\n",
    "#or train and save new lda model from below command, .\n",
    "lda = TopicModels.train(corpus, 10);\n",
    "#TopicModels.saveLDA(lda, \"nips/lda_obj.json\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"learning\", \"networks\", \"training\", \"image\", \"neural\", \"deep\", \"model\", \"network\", \"images\", \"layer\"]\n",
      "----------------------\n",
      "Any[\"data\", \"learning\", \"model\", \"samples\", \"features\", \"classification\", \"function\", \"regression\", \"distribution\", \"feature\"]\n",
      "----------------------\n",
      "Any[\"algorithm\", \"learning\", \"probability\", \"error\", \"set\", \"distribution\", \"number\", \"regret\", \"case\", \"one\"]\n",
      "----------------------\n",
      "Any[\"graph\", \"algorithm\", \"nodes\", \"set\", \"node\", \"clustering\", \"data\", \"model\", \"pages\", \"algorithms\"]\n",
      "----------------------\n",
      "Any[\"network\", \"neural\", \"networks\", \"training\", \"learning\", \"units\", \"system\", \"output\", \"input\", \"hidden\"]\n",
      "----------------------\n",
      "Any[\"model\", \"inference\", \"models\", \"distribution\", \"latent\", \"variational\", \"log\", \"posterior\", \"data\", \"bayesian\"]\n",
      "----------------------\n",
      "Any[\"matrix\", \"linear\", \"random\", \"kernel\", \"approximation\", \"error\", \"problem\", \"points\", \"number\", \"algorithm\"]\n",
      "----------------------\n",
      "Any[\"algorithm\", \"optimization\", \"theorem\", \"function\", \"gradient\", \"convergence\", \"convex\", \"learning\", \"bound\", \"algorithms\"]\n",
      "----------------------\n",
      "Any[\"model\", \"figure\", \"neurons\", \"input\", \"layer\", \"information\", \"activity\", \"visual\", \"neuron\", \"pattern\"]\n",
      "----------------------\n",
      "Any[\"policy\", \"learning\", \"state\", \"reward\", \"reinforcement\", \"action\", \"agent\", \"value\", \"function\", \"actions\"]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "topics, proportions = TopicModels.show_topics(lda, corpus, 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top equal number of docs for each topic(number of docs/number of topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distributions = TopicModels.sortedTopDocsForTopics(lda, corpus);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopicModels.Polya(10, TopicModels.Dirichlet(10, [0.579974296129749, 0.5744191180525104, 0.32848648063939023, 0.3135048762874856, 0.3534344433827259, 0.4007397684235953, 0.32384814477454843, 0.393391052177399, 0.4892796297821862, 0.7773404107210861], 4.534418220370676), [0, 142, 1108, 21, 23, 18, 36, 996, 197, 244], 2785)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.topicPolya[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08774845680767072"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TopicModels.topicPredict(lda, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileKPDoc = \"nips/kp/simplified_last_1000_keyphrases_clean.json\"\n",
    "fileEMB = \"nips/kp/1000_docs_keyphrase_embedding.json\"\n",
    "fileSim = \"nips/kp/1000_docs_kp_similarity_python.json\"\n",
    "fileKP = \"nips/kp/keyphrases_from_python.json\"\n",
    "kp = TopicModels.load_keyphrase(fileKPDoc, fileEMB, fileSim, fileKP);\n",
    "# Took 0:54 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_kp, docs_have = TopicModels.top_x_kp_of_topic_m(kp, topic_distributions, 5, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict{Any,Any}(\"machine learning\" => Any[\"machine learning\", \"meta - learning\", \"parallel machine learning\", \"human machine learning\", \"neural programming\", \"neural logic programming\", \"computational intelligence\", \"training algorithms\"])\n",
      "Any[121, 128, 161, 180, 201, 205, 218, 294, 320, 390, 471, 603, 627, 645, 703]"
     ]
    }
   ],
   "source": [
    "println(sort(cluster_kp[4]))\n",
    "print(sort(docs_have[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopicModels.Polya(10, TopicModels.Dirichlet(10, [0.37874374128870947, 0.5164471077484565, 0.6415088998692902, 0.35160601036829925, 0.654889287463685, 0.36340530184332687, 0.5354276647937665, 0.44829370150100706, 0.37649809841356136, 0.2613126833707], 4.528132496660802), [1917, 60, 43, 146, 95, 103, 630, 23, 279, 0], 3296)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.topicPolya[121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopicModels.Polya(10, TopicModels.Dirichlet(10, [0.37874374128870947, 0.5164471077484565, 0.6415088998692902, 0.35160601036829925, 0.654889287463685, 0.36340530184332687, 0.5354276647937665, 0.44829370150100706, 0.37649809841356136, 0.2613126833707], 4.528132496660802), [1305, 311, 282, 68, 249, 48, 39, 174, 16, 351], 2843)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.topicPolya[645]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopicModels.apply_refinement(lda, corpus, \"R_kp\", 4, 1, kp); # Take 2:30 mints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopicModels.Polya(10, TopicModels.Dirichlet(10, [1.0e-7, 0.5164471077484565, 0.6415088998692902, 0.35160601036829925, 0.654889287463685, 0.36340530184332687, 0.5354276647937665, 0.44829370150100706, 0.37649809841356136, 0.2613126833707], 4.149388855372093), [0, 236, 28, 511, 493, 237, 789, 41, 764, 197], 3296)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.topicPolya[121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"networks\", \"image\", \"training\", \"learning\", \"neural\", \"deep\", \"network\", \"model\", \"images\", \"layer\"]\n",
      "----------------------\n",
      "Any[\"data\", \"learning\", \"model\", \"samples\", \"classification\", \"features\", \"function\", \"training\", \"regression\", \"feature\"]\n",
      "----------------------\n",
      "Any[\"algorithm\", \"learning\", \"probability\", \"error\", \"distribution\", \"set\", \"number\", \"regret\", \"case\", \"given\"]\n",
      "----------------------\n",
      "Any[\"graph\", \"algorithm\", \"nodes\", \"set\", \"node\", \"clustering\", \"data\", \"model\", \"pages\", \"algorithms\"]\n",
      "----------------------\n",
      "Any[\"network\", \"neural\", \"networks\", \"training\", \"learning\", \"input\", \"system\", \"output\", \"units\", \"one\"]\n",
      "----------------------\n",
      "Any[\"model\", \"inference\", \"distribution\", \"models\", \"latent\", \"variational\", \"log\", \"posterior\", \"data\", \"gaussian\"]\n",
      "----------------------\n",
      "Any[\"matrix\", \"linear\", \"random\", \"kernel\", \"algorithm\", \"error\", \"approximation\", \"problem\", \"points\", \"number\"]\n",
      "----------------------\n",
      "Any[\"algorithm\", \"optimization\", \"theorem\", \"function\", \"gradient\", \"convergence\", \"convex\", \"learning\", \"bound\", \"algorithms\"]\n",
      "----------------------\n",
      "Any[\"model\", \"figure\", \"neurons\", \"input\", \"image\", \"activity\", \"visual\", \"information\", \"neuron\", \"cells\"]\n",
      "----------------------\n",
      "Any[\"learning\", \"policy\", \"state\", \"reward\", \"reinforcement\", \"action\", \"agent\", \"tasks\", \"task\", \"function\"]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "TopicModels.show_topics(lda, corpus, 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "addDoc (generic function with 1 method)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function addDoc(self, corpus, docs, topic)\n",
    "    if typeof(docs) == Int64\n",
    "        docs = [docs]\n",
    "    end\n",
    "    for doc_idx in docs\n",
    "        param = copy(self.topicPolya[doc_idx].dir.alpha)\n",
    "        difference = maximum(self.topicPolya[doc_idx].n) - self.topicPolya[doc_idx].n[topic]\n",
    "        param[topic] = self.topicPolya[doc_idx].dir.alpha[topic] + difference\n",
    "        for w in enumerate(corpus.documents[doc_idx])\n",
    "            if self.Samples[doc_idx][w[1]]!=topic\n",
    "                TopicModels.removeSample(self, doc_idx, w[1], self.Samples[doc_idx][w[1]])\n",
    "                self.Samples[doc_idx][w[1]] = 0\n",
    "            end\n",
    "        end\n",
    "        self.topicPolya[doc_idx].dir = TopicModels.Dirichlet(param)    \n",
    "    end          \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 10, 14, 16, 17, 18, 22, 34, 38, 39, 45, 47, 49, 50, 52, 55, 81, 86, 88, 92, 121, 128, 148, 158, 161, 165, 166, 168, 179, 180, 190, 191, 194, 199, 201, 205, 211, 218, 223, 246, 272, 282, 294, 306, 314, 320, 321, 348, 354, 368, 369, 372, 377, 378, 390, 402, 412, 427, 433, 441, 442, 471, 482, 487, 498, 502, 510, 516, 517, 534, 540, 541, 554, 556, 557, 570, 587, 589, 592, 596, 597, 600, 603, 627, 629, 645, 652, 658, 666, 668, 671, 678, 681, 682, 691, 697, 698, 703, 855]\n"
     ]
    }
   ],
   "source": [
    "println(sort(topic_distributions[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopicModels.Polya(10, TopicModels.Dirichlet(10, [0.37874374128870947, 0.5164471077484565, 0.6415088998692902, 0.35160601036829925, 0.654889287463685, 0.36340530184332687, 0.5354276647937665, 0.44829370150100706, 0.37649809841356136, 0.2613126833707], 4.528132496660802), [5, 504, 549, 156, 14, 55, 1033, 521, 0, 1], 2838)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.topicPolya[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "addDoc(lda, corpus, 5, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopicModels.gibbsSampling(lda, corpus.documents, 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopicModels.Polya(10, TopicModels.Dirichlet(10, [1028.3787437412886, 0.5164471077484565, 0.6415088998692902, 0.35160601036829925, 0.654889287463685, 0.36340530184332687, 0.5354276647937665, 0.44829370150100706, 0.37649809841356136, 0.2613126833707], 1032.5281324966606), [662, 270, 438, 119, 3, 0, 784, 558, 3, 1], 2838)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.topicPolya[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distributions = TopicModels.sortedTopDocsForTopics(lda, corpus);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 10, 14, 16, 17, 18, 22, 34, 38, 39, 40, 45, 47, 49, 50, 52, 55, 67, 81, 86, 88, 92, 95, 119, 143, 148, 158, 165, 166, 168, 179, 188, 190, 191, 194, 199, 211, 223, 246, 256, 272, 282, 306, 314, 321, 334, 348, 354, 368, 369, 372, 377, 378, 402, 412, 427, 433, 441, 442, 475, 482, 487, 498, 501, 502, 510, 515, 516, 517, 534, 540, 541, 543, 552, 554, 556, 557, 570, 587, 589, 592, 596, 597, 600, 621, 629, 642, 652, 658, 666, 668, 671, 678, 681, 682, 691, 697, 698]\n"
     ]
    }
   ],
   "source": [
    "println(sort(topic_distributions[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 13, 19, 21, 22, 29, 32, 36, 39, 44, 47, 54, 58, 63, 74, 80, 82, 100, 102, 110, 112, 113, 123, 128, 129, 137, 139, 169, 172, 193, 197, 206, 219, 226, 234, 235, 243, 256, 268, 271, 294, 303, 304, 311, 323, 326, 344, 355, 372, 381, 390, 391, 393, 401, 408, 431, 438, 442, 445, 449, 460, 477, 480, 517, 530, 535, 543, 547, 548, 555, 558, 561, 563, 571, 575, 584, 595, 624, 643, 649, 665, 666, 667, 684, 687, 695, 703, 717, 752, 783, 794, 841, 904, 923, 936, 954, 955, 971, 986, 989]\n"
     ]
    }
   ],
   "source": [
    "println(sort(topic_distributions[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopicModels.Polya(10, TopicModels.Dirichlet(10, [0.37874374128870947, 0.5164471077484565, 0.6415088998692902, 0.35160601036829925, 0.654889287463685, 0.36340530184332687, 0.5354276647937665, 0.44829370150100706, 0.37649809841356136, 0.2613126833707], 4.528132496660802), [84, 48, 119, 125, 660, 3, 20, 5, 61, 1], 1126)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.topicPolya[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "addDoc(lda, corpus, 9, 2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopicModels.gibbsSampling(lda, corpus.documents, 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopicModels.Polya(10, TopicModels.Dirichlet(10, [0.37874374128870947, 612.5164471077485, 0.6415088998692902, 0.35160601036829925, 0.654889287463685, 0.36340530184332687, 0.5354276647937665, 0.44829370150100706, 0.37649809841356136, 0.2613126833707], 616.5281324966609), [52, 361, 41, 83, 531, 3, 13, 4, 38, 0], 1126)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.topicPolya[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distributions = TopicModels.sortedTopDocsForTopics(lda, corpus);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 9, 13, 19, 21, 22, 29, 32, 36, 39, 44, 47, 54, 58, 63, 74, 80, 82, 100, 102, 110, 112, 113, 123, 128, 129, 137, 139, 169, 172, 193, 206, 219, 226, 234, 235, 243, 256, 268, 271, 276, 294, 303, 304, 311, 320, 323, 326, 344, 355, 372, 381, 389, 390, 391, 393, 401, 408, 422, 428, 431, 438, 442, 445, 449, 460, 471, 480, 485, 504, 517, 535, 543, 547, 548, 553, 555, 558, 561, 563, 571, 584, 595, 624, 643, 649, 665, 666, 667, 684, 687, 695, 703, 728, 783, 841, 904, 936, 955, 989]\n"
     ]
    }
   ],
   "source": [
    "println(sort(topic_distributions[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 66, 109, 131, 153, 253, 383, 407, 418, 429, 462, 484, 507, 594, 616, 639, 661, 683, 714, 716, 724, 729, 731, 734, 735, 737, 741, 742, 743, 744, 746, 748, 754, 755, 760, 761, 764, 766, 771, 776, 778, 779, 781, 782, 786, 791, 793, 800, 802, 807, 808, 809, 813, 814, 815, 817, 819, 821, 822, 825, 828, 831, 838, 839, 844, 858, 864, 866, 867, 874, 877, 878, 880, 881, 885, 888, 889, 905, 907, 913, 917, 918, 922, 927, 933, 935, 941, 944, 949, 963, 965, 966, 968, 973, 975, 980, 984, 987, 988, 992]\n"
     ]
    }
   ],
   "source": [
    "println(sort(topic_distributions[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopicModels.Polya(10, TopicModels.Dirichlet(10, [0.37874374128870947, 0.5164471077484565, 0.6415088998692902, 0.35160601036829925, 0.654889287463685, 0.36340530184332687, 0.5354276647937665, 0.44829370150100706, 0.37649809841356136, 0.2613126833707], 4.528132496660802), [1160, 605, 482, 1, 92, 484, 22, 275, 0, 35], 3156)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.topicPolya[67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "addDoc(lda, corpus, 67, 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopicModels.gibbsSampling(lda, corpus.documents, 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopicModels.Polya(10, TopicModels.Dirichlet(10, [0.37874374128870947, 0.5164471077484565, 0.6415088998692902, 0.35160601036829925, 1068.6548892874637, 0.36340530184332687, 0.5354276647937665, 0.44829370150100706, 0.37649809841356136, 0.2613126833707], 1072.5281324966609), [703, 452, 377, 0, 1059, 281, 20, 249, 0, 15], 3156)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.topicPolya[67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 66, 67, 109, 153, 253, 383, 407, 418, 429, 462, 484, 507, 594, 616, 639, 661, 683, 712, 714, 724, 729, 731, 734, 735, 737, 741, 742, 743, 744, 746, 748, 754, 760, 764, 766, 771, 776, 778, 779, 781, 782, 786, 791, 793, 800, 802, 804, 807, 808, 809, 813, 814, 815, 817, 819, 821, 822, 825, 828, 831, 838, 839, 844, 854, 858, 864, 866, 867, 874, 877, 878, 880, 881, 885, 888, 889, 896, 905, 907, 913, 917, 918, 922, 927, 935, 941, 944, 949, 957, 963, 965, 966, 968, 973, 975, 984, 987, 988, 992]\n"
     ]
    }
   ],
   "source": [
    "topic_distributions = TopicModels.sortedTopDocsForTopics(lda, corpus);\n",
    "println(sort(topic_distributions[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save LDA object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18214193"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_dict = Dict()\n",
    "lda_dict[\"numIteration\"] = lda.numIteration\n",
    "lda_dict[\"M\"] = lda.M\n",
    "lda_dict[\"topicDir_param\"] = lda.topicDir.alpha\n",
    "lda_dict[\"wordPolya_n\"] = [i.n for i in lda.wordPolya]\n",
    "lda_dict[\"X\"] = lda.X\n",
    "lda_dict[\"topicPolya_n\"] = [i.n for i in lda.topicPolya]\n",
    "lda_dict[\"Samples\"] = lda.Samples\n",
    "lda_json_string = JSON.json(lda_dict)\n",
    "\n",
    "open(\"lda_obj.json\",\"w\") do f \n",
    "    write(f, lda_json_string) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lda1_raw = JSON.parsefile(\"lda_obj.json\");\n",
    "numIteration = lda1_raw[\"numIteration\"]\n",
    "M = lda1_raw[\"M\"]\n",
    "topicDir = TopicModels.Dirichlet(lda1_raw[\"topicDir_param\"])\n",
    "wordPolya = [TopicModels.Polya(TopicModels.Dirichlet(length(i), 0.01), i) for i in lda1_raw[\"wordPolya_n\"]]\n",
    "X = lda1_raw[\"X\"]\n",
    "topicPolya = [TopicModels.Polya(topicDir, i) for i in lda1_raw[\"topicPolya_n\"]]\n",
    "Samples = lda1_raw[\"Samples\"]\n",
    "lda_obj = TopicModels.LDA(numIteration, M, topicDir, wordPolya, X, topicPolya, Samples);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Coherence, add and remove word refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.7308979585130184"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TopicModels.topic_coherence(corpus, topics, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopicModels.apply_refinement(lda, corpus, \"remove\", \"model\", 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"variable\", \"causal\", \"data\", \"group\", \"test\", \"individual\", \"distribution\", \"information\", \"outcome\", \"hypothesis\"]\n",
      "[0.01333, 0.00915, 0.00838, 0.00817, 0.00716, 0.00677, 0.00609, 0.00606, 0.00596, 0.00581]\n",
      "----------------------\n",
      "Any[\"algorithm\", \"time\", \"problem\", \"one\", \"number\", \"also\", \"result\", \"value\", \"given\", \"two\"]\n",
      "[0.03303, 0.01766, 0.01364, 0.01102, 0.01081, 0.00674, 0.00599, 0.00536, 0.00536, 0.00493]\n",
      "----------------------\n",
      "Any[\"image\", \"network\", \"model\", \"convolutional\", \"training\", \"adversarial\", \"learning\", \"deep\", \"sample\", \"loss\"]\n",
      "[0.02886, 0.017, 0.00936, 0.00924, 0.00892, 0.00814, 0.00783, 0.0075, 0.00735, 0.00707]\n",
      "----------------------\n",
      "Any[\"error\", \"memory\", \"noise\", \"data\", \"distributed\", \"block\", \"bit\", \"vector\", \"performance\", \"code\"]\n",
      "[0.01721, 0.01412, 0.01332, 0.00967, 0.00902, 0.00875, 0.00864, 0.00794, 0.00773, 0.00715]\n",
      "----------------------\n",
      "Any[\"network\", \"unit\", \"neural\", \"input\", \"weight\", \"output\", \"learning\", \"hidden\", \"training\", \"state\"]\n",
      "[0.05848, 0.02447, 0.01927, 0.01882, 0.01732, 0.01724, 0.01314, 0.01215, 0.01033, 0.00933]\n",
      "----------------------\n",
      "Any[\"policy\", \"learning\", \"state\", \"action\", \"reward\", \"agent\", \"reinforcement\", \"arm\", \"task\", \"value\"]\n",
      "[0.03077, 0.02333, 0.02178, 0.01924, 0.01823, 0.01451, 0.01155, 0.00858, 0.00831, 0.00816]\n",
      "----------------------\n",
      "Any[\"regret\", \"algorithm\", \"online\", \"learning\", \"bandit\", \"loss\", \"bound\", \"function\", \"round\", \"player\"]\n",
      "[0.02419, 0.02191, 0.0176, 0.01431, 0.01237, 0.0121, 0.01117, 0.01007, 0.00867, 0.00781]\n",
      "----------------------\n",
      "Any[\"function\", \"point\", \"equation\", \"error\", \"linear\", \"space\", \"local\", \"vector\", \"case\", \"learning\"]\n",
      "[0.02075, 0.01612, 0.01019, 0.00863, 0.00844, 0.0082, 0.0076, 0.00749, 0.00713, 0.00705]\n",
      "----------------------\n",
      "Any[\"bound\", \"theorem\", \"distribution\", \"sample\", \"probability\", \"let\", \"log\", \"result\", \"error\", \"proof\"]\n",
      "[0.0198, 0.01702, 0.01553, 0.01369, 0.01133, 0.01054, 0.01051, 0.0099, 0.00807, 0.00763]\n",
      "----------------------\n",
      "Any[\"neuron\", \"cell\", \"model\", \"response\", \"neural\", \"activity\", \"time\", \"spike\", \"system\", \"signal\"]\n",
      "[0.01951, 0.0149, 0.01434, 0.01009, 0.00916, 0.00914, 0.00815, 0.00726, 0.00714, 0.00669]\n",
      "----------------------\n",
      "Any[\"network\", \"neural\", \"training\", \"layer\", \"deep\", \"learning\", \"gradient\", \"parameter\", \"weight\", \"method\"]\n",
      "[0.04283, 0.02526, 0.0241, 0.02409, 0.02091, 0.02022, 0.01775, 0.00926, 0.0092, 0.0091]\n",
      "----------------------\n",
      "Any[\"model\", \"distribution\", \"inference\", \"data\", \"process\", \"posterior\", \"variational\", \"parameter\", \"variable\", \"bayesian\"]\n",
      "[0.0414, 0.01713, 0.01569, 0.01369, 0.01287, 0.01263, 0.01161, 0.01039, 0.01004, 0.0099]\n",
      "----------------------\n",
      "Any[\"kernel\", \"learning\", \"function\", \"regression\", \"loss\", \"machine\", \"feature\", \"space\", \"method\", \"approximation\"]\n",
      "[0.04227, 0.02353, 0.0213, 0.02076, 0.01437, 0.01309, 0.01084, 0.0102, 0.01019, 0.00892]\n",
      "----------------------\n",
      "Any[\"object\", \"model\", \"image\", \"map\", \"figure\", \"representation\", \"information\", \"visual\", \"user\", \"location\"]\n",
      "[0.01487, 0.01423, 0.01296, 0.01044, 0.01044, 0.01017, 0.00843, 0.00752, 0.00733, 0.00689]\n",
      "----------------------\n",
      "Any[\"graph\", \"node\", \"algorithm\", \"clustering\", \"cluster\", \"edge\", \"function\", \"set\", \"network\", \"model\"]\n",
      "[0.03165, 0.029, 0.01854, 0.01656, 0.01598, 0.0146, 0.01288, 0.01247, 0.00889, 0.00814]\n",
      "----------------------\n",
      "Any[\"model\", \"task\", \"learning\", \"attention\", \"sequence\", \"vector\", \"language\", \"neural\", \"word\", \"question\"]\n",
      "[0.02283, 0.01793, 0.01183, 0.01039, 0.01014, 0.00891, 0.00884, 0.00874, 0.00862, 0.00752]\n",
      "----------------------\n",
      "Any[\"data\", \"set\", \"method\", \"feature\", \"approach\", \"point\", \"performance\", \"datasets\", \"distance\", \"selection\"]\n",
      "[0.03534, 0.01989, 0.01901, 0.01838, 0.0126, 0.00975, 0.00796, 0.00784, 0.00754, 0.00743]\n",
      "----------------------\n",
      "Any[\"matrix\", \"rank\", \"tensor\", \"spectral\", \"method\", \"covariance\", \"sparse\", \"column\", \"signal\", \"decomposition\"]\n",
      "[0.0769, 0.01262, 0.01251, 0.01177, 0.01166, 0.0093, 0.00911, 0.00875, 0.00758, 0.0073]\n",
      "----------------------\n",
      "Any[\"optimization\", \"gradient\", \"method\", \"algorithm\", \"problem\", \"convergence\", \"convex\", \"iteration\", \"function\", \"stochastic\"]\n",
      "[0.02342, 0.02255, 0.02022, 0.01895, 0.01658, 0.01657, 0.01595, 0.01299, 0.01239, 0.01127]\n",
      "----------------------\n",
      "Any[\"model\", \"training\", \"prediction\", \"learning\", \"class\", \"classifier\", \"classification\", \"data\", \"feature\", \"label\"]\n",
      "[0.02777, 0.0205, 0.01664, 0.01537, 0.01535, 0.01453, 0.01351, 0.01289, 0.01285, 0.0128]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "topics, proportions = TopicModels.show_topics(corpus, lda, 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.6578622641487515"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TopicModels.topic_coherence(corpus, topics, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopicModels.apply_refinement(corpus, lda, \"add\", \"node\", 2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopicModels.show_topics(corpus, lda, 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the top topic for each doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function topic_of_each_doc(lda, corpus)\n",
    "    top_topic_for_each_doc = []\n",
    "    for i in 1:corpus.document_size\n",
    "        top_val = 0\n",
    "        top_topic = 0\n",
    "        for j in 1:lda.M\n",
    "            v = TopicModels.lda_topicPredict(i, j, lda)\n",
    "            if v>=top_val\n",
    "                top_val = v\n",
    "                top_topic = j\n",
    "            end\n",
    "        end\n",
    "        push!(top_topic_for_each_doc, top_topic)\n",
    "    end\n",
    "    return top_topic_for_each_doc\n",
    "end\n",
    "#top_topic_for_each_doc = topic_of_each_doc(corpus, lda);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999-element Array{Any,1}:\n",
       "  2\n",
       "  6\n",
       "  2\n",
       "  1\n",
       "  6\n",
       "  4\n",
       "  9\n",
       "  1\n",
       "  6\n",
       "  5\n",
       "  1\n",
       "  5\n",
       "  5\n",
       "  ⋮\n",
       "  9\n",
       "  6\n",
       " 10\n",
       "  6\n",
       " 10\n",
       " 10\n",
       " 10\n",
       " 10\n",
       "  6\n",
       " 10\n",
       " 10\n",
       "  5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topic_for_each_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "view_top_docs (generic function with 1 method)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function view_top_docs(top_topic_for_each_doc, document_file, topic)\n",
    "    papers = CSV.read(document_file, DataFrame);\n",
    "    titles = papers.title\n",
    "    titles = titles[length(titles)-corpus.document_size+1:length(titles)]\n",
    "    for (idx, t) in enumerate(top_topic_for_each_doc)\n",
    "        if t == topic\n",
    "            #println(idx, \" \" , titles[idx])\n",
    "            print(idx, \", \")\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14, 15, 24, 51, 64, 70, 76, 79, "
     ]
    }
   ],
   "source": [
    "using CSV, DataFrames\n",
    "view_top_docs(top_topic_for_each_doc, \"papers.csv\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HLTM remove document implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, no_lemma_docs = TopicModels.preprocess(\"papers.csv\", 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = TopicModels.train(corpus, 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"network\", \"input\", \"networks\", \"training\", \"learning\"]\n",
      "[0.02076, 0.01477, 0.01446, 0.01322, 0.01085]\n",
      "----------------------\n",
      "Any[\"neural\", \"algorithm\", \"data\", \"case\", \"weight\"]\n",
      "[0.01855, 0.01428, 0.01418, 0.01023, 0.00927]\n",
      "----------------------\n",
      "Any[\"state\", \"model\", \"learning\", \"models\", \"number\"]\n",
      "[0.01429, 0.01354, 0.01193, 0.01107, 0.00774]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "topics, proportions = TopicModels.show_topics(corpus, lda, 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{TopicModels.Polya,1}:\n",
       " TopicModels.Polya(5280, TopicModels.Dirichlet(5280, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01  …  0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01], 52.800000000000004), [7, 36, 8, 10, 14, 128, 17, 7, 0, 0  …  1, 0, 0, 0, 0, 2, 0, 0, 0, 1], 9628)\n",
       " TopicModels.Polya(5280, TopicModels.Dirichlet(5280, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01  …  0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01], 52.800000000000004), [0, 0, 0, 0, 0, 13, 0, 0, 0, 7  …  0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 9330)\n",
       " TopicModels.Polya(5280, TopicModels.Dirichlet(5280, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01  …  0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01], 52.800000000000004), [0, 0, 0, 0, 0, 0, 0, 0, 6, 0  …  0, 1, 1, 2, 2, 0, 0, 1, 1, 0], 9252)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.wordPolya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Array{TopicModels.Polya,1}:\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [720, 398, 334], 1452)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [111, 370, 1065], 1546)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [1325, 271, 214], 1810)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [963, 138, 561], 1662)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [102, 250, 128], 480)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [559, 274, 422], 1255)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [477, 94, 563], 1134)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [704, 532, 162], 1398)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [106, 693, 242], 1041)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [170, 934, 399], 1503)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [608, 351, 181], 1140)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [544, 1526, 691], 2761)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [143, 131, 592], 866)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [497, 78, 179], 754)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [382, 168, 956], 1506)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [216, 1192, 133], 1541)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [340, 1174, 282], 1796)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [368, 269, 447], 1084)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [948, 137, 536], 1621)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845), [345, 350, 1165], 1860)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.topicPolya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopicModels.Dirichlet(3, [0.6906504672532601, 0.6433493639156528, 0.6922273273374719], 2.0262271585063845)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.topicDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Array{Any,1}:\n",
       " Any[1, 1, 1, 1, 1, 1, 1, 1, 3, 2  …  1, 1, 3, 1, 1, 3, 3, 3, 1, 2]\n",
       " Any[3, 3, 3, 3, 3, 2, 3, 3, 3, 3  …  2, 2, 3, 3, 2, 3, 2, 3, 3, 3]\n",
       " Any[1, 1, 1, 2, 1, 1, 1, 1, 1, 1  …  3, 1, 1, 1, 1, 1, 1, 1, 3, 1]\n",
       " Any[1, 1, 3, 1, 1, 1, 1, 2, 1, 2  …  3, 3, 1, 1, 2, 1, 3, 1, 1, 3]\n",
       " Any[2, 2, 3, 2, 2, 2, 3, 3, 1, 2  …  1, 1, 3, 3, 1, 2, 3, 3, 2, 1]\n",
       " Any[1, 3, 2, 1, 2, 1, 1, 1, 3, 1  …  2, 3, 1, 3, 3, 2, 3, 3, 2, 3]\n",
       " Any[1, 1, 1, 1, 3, 1, 3, 3, 2, 1  …  3, 1, 3, 1, 3, 1, 1, 1, 3, 3]\n",
       " Any[1, 1, 1, 2, 2, 2, 2, 2, 1, 1  …  1, 2, 2, 2, 1, 1, 2, 1, 2, 1]\n",
       " Any[2, 2, 2, 3, 2, 3, 2, 3, 2, 2  …  2, 3, 1, 2, 3, 1, 1, 3, 2, 2]\n",
       " Any[2, 2, 2, 2, 2, 2, 2, 2, 2, 2  …  1, 1, 3, 2, 3, 3, 2, 3, 2, 2]\n",
       " Any[2, 1, 2, 2, 1, 1, 2, 3, 1, 3  …  1, 1, 1, 1, 3, 1, 2, 2, 1, 2]\n",
       " Any[2, 2, 2, 3, 2, 1, 2, 3, 2, 2  …  2, 3, 2, 2, 3, 1, 3, 2, 3, 3]\n",
       " Any[3, 3, 3, 2, 3, 3, 3, 1, 3, 1  …  2, 2, 1, 3, 2, 3, 2, 3, 3, 3]\n",
       " Any[1, 3, 1, 1, 1, 1, 1, 3, 1, 1  …  1, 1, 3, 1, 3, 3, 1, 1, 1, 1]\n",
       " Any[3, 3, 3, 3, 1, 3, 3, 2, 3, 1  …  3, 3, 2, 1, 1, 1, 2, 1, 3, 2]\n",
       " Any[2, 2, 3, 2, 2, 2, 2, 2, 2, 2  …  2, 2, 2, 2, 2, 1, 2, 3, 2, 1]\n",
       " Any[2, 2, 2, 2, 2, 2, 2, 2, 2, 2  …  2, 2, 1, 1, 2, 1, 1, 3, 2, 2]\n",
       " Any[3, 1, 3, 3, 2, 3, 1, 1, 3, 3  …  1, 1, 3, 3, 3, 2, 2, 3, 3, 3]\n",
       " Any[1, 1, 1, 1, 1, 2, 3, 3, 1, 3  …  1, 1, 3, 1, 1, 3, 3, 1, 1, 3]\n",
       " Any[3, 3, 3, 3, 3, 3, 2, 3, 3, 2  …  3, 3, 3, 1, 3, 3, 3, 1, 2, 1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopicModels.apply_refinement(lda, corpus, \"R_D\", 1, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{TopicModels.Polya,1}:\n",
       " TopicModels.Polya(5280, TopicModels.Dirichlet(5280, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01  …  0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01], 52.800000000000004), [0, 0, 0, 0, 0, 39, 0, 0, 0, 0  …  1, 0, 0, 0, 2, 2, 0, 0, 1, 1], 8005)\n",
       " TopicModels.Polya(5280, TopicModels.Dirichlet(5280, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01  …  0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01], 52.800000000000004), [0, 0, 0, 0, 0, 102, 0, 0, 0, 5  …  0, 0, 1, 0, 0, 0, 0, 1, 0, 0], 9991)\n",
       " TopicModels.Polya(5280, TopicModels.Dirichlet(5280, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01  …  0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01], 52.800000000000004), [7, 36, 8, 10, 14, 0, 17, 7, 6, 2  …  0, 1, 0, 2, 0, 0, 1, 0, 0, 0], 10214)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.wordPolya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Array{TopicModels.Polya,1}:\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [1.0e-7, 0.6433493639156528, 0.6922273273374719], 1.3355767912531247), [0, 647, 805], 1452)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [48, 355, 1143], 1546)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [1291, 264, 255], 1810)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [944, 131, 587], 1662)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [78, 235, 167], 480)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [482, 283, 490], 1255)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [480, 84, 570], 1134)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [656, 570, 172], 1398)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [86, 730, 225], 1041)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [120, 1000, 383], 1503)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [619, 344, 177], 1140)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [394, 1715, 652], 2761)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [81, 134, 651], 866)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [497, 88, 169], 754)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [301, 162, 1043], 1506)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [165, 1250, 126], 1541)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [197, 1240, 359], 1796)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [319, 293, 472], 1084)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [962, 137, 522], 1621)\n",
       " TopicModels.Polya(3, TopicModels.Dirichlet(3, [0.4866968873359249, 0.5891369773347052, 0.6502990374700215], 1.7261329021406515), [285, 329, 1246], 1860)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.topicPolya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Array{Any,1}:\n",
       " Any[3, 3, 3, 3, 3, 2, 3, 3, 3, 2  …  3, 2, 2, 2, 2, 3, 3, 2, 2, 2]\n",
       " Any[3, 2, 3, 3, 3, 3, 3, 3, 3, 3  …  2, 2, 3, 3, 2, 3, 3, 2, 3, 3]\n",
       " Any[1, 1, 1, 2, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 3, 2, 3, 3]\n",
       " Any[2, 1, 1, 1, 1, 3, 1, 1, 1, 3  …  3, 3, 1, 1, 2, 1, 1, 1, 1, 3]\n",
       " Any[2, 2, 1, 2, 2, 2, 3, 2, 3, 2  …  1, 1, 3, 3, 1, 2, 3, 3, 2, 2]\n",
       " Any[1, 3, 2, 1, 2, 3, 3, 1, 3, 3  …  2, 3, 3, 3, 3, 2, 3, 3, 2, 1]\n",
       " Any[1, 1, 1, 1, 3, 1, 3, 3, 2, 3  …  1, 2, 3, 1, 3, 1, 1, 1, 3, 3]\n",
       " Any[1, 1, 2, 2, 1, 2, 2, 2, 1, 1  …  3, 2, 1, 2, 1, 1, 2, 1, 2, 1]\n",
       " Any[2, 2, 2, 2, 2, 1, 2, 3, 2, 2  …  2, 2, 3, 2, 3, 1, 3, 3, 2, 2]\n",
       " Any[2, 2, 2, 2, 2, 2, 2, 2, 2, 2  …  1, 2, 3, 2, 3, 3, 2, 1, 2, 2]\n",
       " Any[1, 1, 2, 2, 1, 1, 2, 1, 1, 1  …  2, 1, 1, 2, 3, 1, 2, 2, 1, 1]\n",
       " Any[2, 2, 2, 2, 2, 1, 2, 3, 2, 2  …  2, 3, 2, 2, 3, 2, 3, 2, 3, 2]\n",
       " Any[3, 3, 3, 2, 3, 3, 3, 2, 3, 2  …  2, 2, 3, 3, 2, 3, 2, 3, 3, 3]\n",
       " Any[1, 3, 3, 1, 1, 1, 1, 3, 1, 1  …  1, 1, 3, 1, 1, 3, 1, 1, 1, 1]\n",
       " Any[3, 3, 3, 3, 3, 3, 3, 3, 3, 1  …  3, 3, 2, 3, 1, 1, 3, 3, 3, 1]\n",
       " Any[2, 2, 1, 2, 2, 2, 2, 2, 2, 2  …  2, 1, 2, 2, 2, 2, 1, 3, 2, 1]\n",
       " Any[2, 2, 2, 2, 2, 2, 2, 2, 1, 2  …  2, 2, 1, 1, 2, 3, 2, 3, 2, 3]\n",
       " Any[3, 3, 3, 3, 2, 3, 1, 3, 3, 3  …  1, 3, 3, 3, 1, 2, 1, 3, 3, 3]\n",
       " Any[1, 1, 1, 1, 1, 2, 3, 3, 1, 3  …  2, 1, 3, 1, 3, 1, 3, 1, 3, 3]\n",
       " Any[3, 3, 3, 3, 3, 3, 2, 3, 3, 3  …  3, 3, 3, 1, 3, 3, 1, 1, 2, 3]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Topic Labeling Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Activating\u001b[22m\u001b[39m environment at `~/Documents/Study/Git_Personal/julia_bayes/TopicModels/Project.toml`\n",
      "┌ Info: Precompiling TopicModels [cfcb1801-bb54-4f1b-8249-336c042d2c46]\n",
      "└ @ Base loading.jl:1278\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "using Distances\n",
    "using StatsBase\n",
    "using DataStructures\n",
    "using ProgressMeter\n",
    "Pkg.activate(\"TopicModels\")\n",
    "import TopicModels\n",
    "#using PyCall\n",
    "\n",
    "#corpora = pyimport(\"gensim.corpora\")\n",
    "#ch = pyimport(\"gensim.models.coherencemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, no_lemma_docs = TopicModels.preprocess(\"papers.csv\", 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_label_distribution = TopicModels.train_phrase_model(no_lemma_docs, corpus.vocabulary, 10, true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = TopicModels.train(corpus, 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, proportions = TopicModels.show_topics(corpus, lda, corpus.vocab_count, false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"input\", \"figure\", \"current\", \"motion\", \"direction\", \"analog\", \"single\", \"voltage\", \"synapses\", \"layer\"]\n",
      "Any[\"state\", \"learning\", \"algorithm\", \"states\", \"probability\", \"function\", \"convergence\", \"value\", \"algorithms\", \"process\"]\n",
      "Any[\"network\", \"neural\", \"units\", \"networks\", \"output\", \"training\", \"control\", \"figure\", \"architecture\", \"model\"]\n",
      "Any[\"model\", \"system\", \"two\", \"field\", \"one\", \"visual\", \"weights\", \"time\", \"first\", \"figure\"]\n",
      "Any[\"recognition\", \"training\", \"distance\", \"input\", \"information\", \"used\", \"pattern\", \"figure\", \"performance\", \"test\"]\n",
      "Any[\"data\", \"algorithm\", \"problem\", \"set\", \"models\", \"new\", \"given\", \"mixture\", \"classification\", \"points\"]\n",
      "Any[\"image\", \"network\", \"networks\", \"mlp\", \"features\", \"road\", \"images\", \"model\", \"objects\", \"layer\"]\n",
      "Any[\"learning\", \"space\", \"generalization\", \"case\", \"training\", \"distribution\", \"examples\", \"sequence\", \"error\", \"matrix\"]\n",
      "Any[\"memory\", \"neurons\", \"learning\", \"computational\", \"model\", \"activation\", \"tasks\", \"neuron\", \"synaptic\", \"different\"]\n",
      "Any[\"neural\", \"error\", \"networks\", \"number\", \"function\", \"network\", \"set\", \"data\", \"results\", \"linear\"]\n"
     ]
    }
   ],
   "source": [
    "for t in topics\n",
    "    println(t[1:10])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mComputing...100%|███████████████████████████████████████| Time: 0:44:04\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 10 entries:\n",
       "  7  => Array{Any,1}[[\"hidden_layer\", 2.78953, [0.00218779, 0.0116524, 0.010924…\n",
       "  4  => Array{Any,1}[[\"can_be\", 2.56588, [0.00419746, 0.00339036, 0.00328274, 0…\n",
       "  9  => Array{Any,1}[[\"it_is\", 2.80177, [0.00166972, 0.000501499, 0.00517437, 0…\n",
       "  10 => Array{Any,1}[[\"can_be\", 1.9869, [0.000646218, 0.00269087, 0.00172235, 0…\n",
       "  2  => Array{Any,1}[[\"can_be\", 2.29343, [0.00258326, 0.00559643, 0.0037132, 0.…\n",
       "  3  => Array{Any,1}[[\"neural_network\", 2.24291, [0.00704973, 0.00472876, 0.001…\n",
       "  5  => Array{Any,1}[[\"training_data\", 2.66596, [0.00135389, 0.00968897, 0.0006…\n",
       "  8  => Array{Any,1}[[\"can_be\", 2.3162, [0.00559643, 0.00172235, 0.00139951, 0.…\n",
       "  6  => Array{Any,1}[[\"can_be\", 2.27858, [0.00382081, 0.0037132, 0.00349797, 0.…\n",
       "  1  => Array{Any,1}[[\"has_been\", 2.75192, [0.0031105, 0.000865275, 0.00328321,…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#New code\n",
    "top_3_bi_tri_labels_only = TopicModels.label_ranking(candidate_label_distribution, topics, proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"has_been\", \"can_be\", \"such_as\"]\n",
      "[\"can_be\", \"value_function\", \"note_that\"]\n",
      "[\"neural_network\", \"error_between\", \"after_training\"]\n",
      "[\"can_be\", \"is_not\", \"has_been\"]\n",
      "[\"training_data\", \"this_is\", \"can_be\"]\n",
      "[\"can_be\", \"it_is\", \"em_algorithm\"]\n",
      "[\"hidden_layer\", \"video_camera\", \"input_features\"]\n",
      "[\"can_be\", \"we_have\", \"it_is\"]\n",
      "[\"it_is\", \"such_as\", \"biological_neural\"]\n",
      "[\"can_be\", \"it_is\", \"this_is\"]\n"
     ]
    }
   ],
   "source": [
    "# For comparing all words of topic distributions with base_count_kl = 0.01\n",
    "for (pos, i) in enumerate(topics)\n",
    "    println([l[1] for l in top_3_bi_tri_labels_only[pos]])\n",
    "    #println(i[1:10]) \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For comparing top n words of topic distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"procedureoptimal\", \"steadily\", \"glennygedacuk\"]\n",
      "Any[\"figure\", \"however\", \"examples\", \"noise\", \"case\", \"point\", \"equation\", \"approximation\", \"rule\", \"given\"]\n",
      "[\"validityinterval\", \"breastcancerwisc\", \"uel\"]\n",
      "Any[\"networks\", \"rules\", \"neural\", \"units\", \"network\", \"mlp\", \"hidden\", \"rule\", \"training\", \"prediction\"]\n",
      "[\"datadriven\", \"irrespective\", \"distort\"]\n",
      "Any[\"image\", \"tasks\", \"object\", \"algorithm\", \"images\", \"one\", \"objects\", \"models\", \"view\", \"learn\"]\n",
      "[\"qlg\", \"mbl\", \"vgo\"]\n",
      "Any[\"wta\", \"input\", \"current\", \"voltage\", \"gate\", \"inversion\", \"source\", \"floating\", \"correlogram\", \"connectivity\"]\n",
      "[\"anatolviical\", \"ity\", \"limonenelinalool\"]\n",
      "Any[\"model\", \"models\", \"activation\", \"inhibitory\", \"output\", \"receptor\", \"layer\", \"excitatory\", \"module\", \"cell\"]\n",
      "[\"jointangle\", \"cameradriven\", \"orderly\"]\n",
      "Any[\"units\", \"memory\", \"unit\", \"patterns\", \"number\", \"pattern\", \"representation\", \"region\", \"joint\", \"active\"]\n",
      "[\"gos\", \"ilx\", \"bkkx\"]\n",
      "Any[\"data\", \"problem\", \"given\", \"one\", \"function\", \"variance\", \"paper\", \"number\", \"mixture\", \"set\"]\n",
      "[\"unreported\", \"bifurcated\", \"contrasting\"]\n",
      "Any[\"cell\", \"analog\", \"figure\", \"chip\", \"neuron\", \"properties\", \"synaptic\", \"neural\", \"new\", \"neurons\"]\n",
      "[\"identification_network\", \"feedback_neural\", \"backpropagating\"]\n",
      "Any[\"network\", \"output\", \"neural\", \"input\", \"networks\", \"figure\", \"control\", \"architecture\", \"feedback\", \"nonlinear\"]\n",
      "[\"metal\", \"monothongal\", \"underfitting\"]\n",
      "Any[\"training\", \"algorithm\", \"set\", \"class\", \"speech\", \"model\", \"neural\", \"vectors\", \"network\", \"classification\"]\n",
      "[\"afscsprojectconnectbench\", \"jackknife\", \"cto\"]\n",
      "Any[\"networks\", \"neural\", \"size\", \"one\", \"results\", \"parameters\", \"functions\", \"since\", \"form\", \"matrix\"]\n",
      "[\"ddo\", \"yasercaltechedu\", \"interprets\"]\n",
      "Any[\"distance\", \"tangent\", \"information\", \"weight\", \"net\", \"used\", \"use\", \"function\", \"transformation\", \"inputs\"]\n",
      "[\"wnt\", \"xvn\", \"xtwv\"]\n",
      "Any[\"error\", \"generalization\", \"learning\", \"space\", \"linear\", \"training\", \"teacher\", \"function\", \"optimal\", \"distribution\"]\n",
      "[\"eyeposition\", \"birds\", \"fanin\"]\n",
      "Any[\"auditory\", \"time\", \"units\", \"weights\", \"network\", \"system\", \"layer\", \"used\", \"two\", \"signal\"]\n",
      "[\"sweeps\", \"perilous\", \"contractionbased\"]\n",
      "Any[\"state\", \"algorithm\", \"states\", \"algorithms\", \"convergence\", \"function\", \"action\", \"policy\", \"markov\", \"value\"]\n",
      "[\"scaleup\", \"maplike\", \"sardines\"]\n",
      "Any[\"input\", \"map\", \"sequence\", \"context\", \"sequences\", \"units\", \"system\", \"feature\", \"representation\", \"word\"]\n",
      "[\"resistant\", \"consolidated\", \"elapsed\"]\n",
      "Any[\"field\", \"learning\", \"visual\", \"motion\", \"motor\", \"model\", \"two\", \"direction\", \"sensory\", \"point\"]\n",
      "[\"bring\", \"meters\", \"retinas\"]\n",
      "Any[\"figure\", \"performance\", \"features\", \"unit\", \"road\", \"information\", \"representations\", \"right\", \"level\", \"new\"]\n",
      "[\"ofreceptor\", \"odorant\", \"spikecoding\"]\n",
      "Any[\"neurons\", \"computational\", \"model\", \"response\", \"simulations\", \"neuron\", \"simulation\", \"number\", \"stem\", \"analysis\"]\n",
      "[\"mccallumccsrochesteredu\", \"inter\", \"suffered\"]\n",
      "Any[\"learning\", \"time\", \"probability\", \"training\", \"machine\", \"error\", \"first\", \"series\", \"order\", \"reinforcement\"]\n"
     ]
    }
   ],
   "source": [
    "# For comparing top 1000 words of topic distributions\n",
    "for (pos, i) in enumerate(topics)\n",
    "    println([l[1] for l in top_3_labels[pos]])\n",
    "    println(i[1:10])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"openversusclosed\", \"procedureoptimal\", \"lksaulopsychemitedu\"]\n",
      "Any[\"figure\", \"however\", \"examples\", \"noise\", \"case\", \"point\", \"equation\", \"approximation\", \"rule\", \"given\"]\n",
      "[\"chowdhury\", \"afscsprojectconnectbench\", \"validityinterval\"]\n",
      "Any[\"networks\", \"rules\", \"neural\", \"units\", \"network\", \"mlp\", \"hidden\", \"rule\", \"training\", \"prediction\"]\n",
      "[\"datadriven\", \"architecuture\", \"neuristique\"]\n",
      "Any[\"image\", \"tasks\", \"object\", \"algorithm\", \"images\", \"one\", \"objects\", \"models\", \"view\", \"learn\"]\n",
      "[\"buccleuch\", \"qlg\", \"mbl\"]\n",
      "Any[\"wta\", \"input\", \"current\", \"voltage\", \"gate\", \"inversion\", \"source\", \"floating\", \"correlogram\", \"connectivity\"]\n",
      "[\"anatolviical\", \"ity\", \"norberto\"]\n",
      "Any[\"model\", \"models\", \"activation\", \"inhibitory\", \"output\", \"receptor\", \"layer\", \"excitatory\", \"module\", \"cell\"]\n",
      "[\"systvol\", \"bartlett\", \"rethworcementlearmng\"]\n",
      "Any[\"units\", \"memory\", \"unit\", \"patterns\", \"number\", \"pattern\", \"representation\", \"region\", \"joint\", \"active\"]\n",
      "[\"nijmegen\", \"psycholinguistik\", \"aonori\"]\n",
      "Any[\"data\", \"problem\", \"given\", \"one\", \"function\", \"variance\", \"paper\", \"number\", \"mixture\", \"set\"]\n",
      "[\"bahram\", \"afscsprojectconnectbench\", \"nonholographic\"]\n",
      "Any[\"cell\", \"analog\", \"figure\", \"chip\", \"neuron\", \"properties\", \"synaptic\", \"neural\", \"new\", \"neurons\"]\n",
      "[\"ujtubt\", \"literaturei\", \"scheduling\"]\n",
      "Any[\"network\", \"output\", \"neural\", \"input\", \"networks\", \"figure\", \"control\", \"architecture\", \"feedback\", \"nonlinear\"]\n",
      "[\"afscsprojectconnectbench\", \"ftpcscmu\", \"psychophysicallymotivated\"]\n",
      "Any[\"training\", \"algorithm\", \"set\", \"class\", \"speech\", \"model\", \"neural\", \"vectors\", \"network\", \"classification\"]\n",
      "[\"afscsprojectconnectbench\", \"cambrdge\", \"rethworcementlearmng\"]\n",
      "Any[\"networks\", \"neural\", \"size\", \"one\", \"results\", \"parameters\", \"functions\", \"since\", \"form\", \"matrix\"]\n",
      "[\"maxmachine\", \"caruanacscmuedu\", \"yasercaltechedu\"]\n",
      "Any[\"distance\", \"tangent\", \"information\", \"weight\", \"net\", \"used\", \"use\", \"function\", \"transformation\", \"inputs\"]\n",
      "[\"wnt\", \"elimination\", \"rethworcementlearmng\"]\n",
      "Any[\"error\", \"generalization\", \"learning\", \"space\", \"linear\", \"training\", \"teacher\", \"function\", \"optimal\", \"distribution\"]\n",
      "[\"openversusclosed\", \"psycholrev\", \"maxmachine\"]\n",
      "Any[\"auditory\", \"time\", \"units\", \"weights\", \"network\", \"system\", \"layer\", \"used\", \"two\", \"signal\"]\n",
      "[\"sweeps\", \"contractionbased\", \"perilous\"]\n",
      "Any[\"state\", \"algorithm\", \"states\", \"algorithms\", \"convergence\", \"function\", \"action\", \"policy\", \"markov\", \"value\"]\n",
      "[\"scaleup\", \"maplike\", \"sardines\"]\n",
      "Any[\"input\", \"map\", \"sequence\", \"context\", \"sequences\", \"units\", \"system\", \"feature\", \"representation\", \"word\"]\n",
      "[\"kaufinann\", \"psychophysicallymotivated\", \"systvol\"]\n",
      "Any[\"field\", \"learning\", \"visual\", \"motion\", \"motor\", \"model\", \"two\", \"direction\", \"sensory\", \"point\"]\n",
      "[\"openversusclosed\", \"afscsprojectconnectbench\", \"rethworcementlearmng\"]\n",
      "Any[\"figure\", \"performance\", \"features\", \"unit\", \"road\", \"information\", \"representations\", \"right\", \"level\", \"new\"]\n",
      "[\"odorant\", \"biochemistry\", \"mathiscscoloradoedu\"]\n",
      "Any[\"neurons\", \"computational\", \"model\", \"response\", \"simulations\", \"neuron\", \"simulation\", \"number\", \"stem\", \"analysis\"]\n",
      "[\"mccallumccsrochesteredu\", \"utomatic\", \"arcidtectures\"]\n",
      "Any[\"learning\", \"time\", \"probability\", \"training\", \"machine\", \"error\", \"first\", \"series\", \"order\", \"reinforcement\"]\n"
     ]
    }
   ],
   "source": [
    "# For comparing top 100 words of topic distributions\n",
    "for (pos, i) in enumerate(topics)\n",
    "    println([l[1] for l in top_3_labels[pos]])\n",
    "    println(i[1:10])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"procedureoptimal\", \"openversusclosed\", \"glennygedacuk\"]\n",
      "Any[\"figure\", \"however\", \"examples\", \"noise\", \"case\", \"point\", \"equation\", \"approximation\", \"rule\", \"given\"]\n",
      "[\"validityinterval\", \"chowdhury\", \"afscsprojectconnectbench\"]\n",
      "Any[\"networks\", \"rules\", \"neural\", \"units\", \"network\", \"mlp\", \"hidden\", \"rule\", \"training\", \"prediction\"]\n",
      "[\"datadriven\", \"architecuture\", \"neuristique\"]\n",
      "Any[\"image\", \"tasks\", \"object\", \"algorithm\", \"images\", \"one\", \"objects\", \"models\", \"view\", \"learn\"]\n",
      "[\"qlg\", \"buccleuch\", \"ioeqo\"]\n",
      "Any[\"wta\", \"input\", \"current\", \"voltage\", \"gate\", \"inversion\", \"source\", \"floating\", \"correlogram\", \"connectivity\"]\n",
      "[\"anatolviical\", \"ity\", \"norberto\"]\n",
      "Any[\"model\", \"models\", \"activation\", \"inhibitory\", \"output\", \"receptor\", \"layer\", \"excitatory\", \"module\", \"cell\"]\n",
      "[\"cameradriven\", \"sloppy\", \"recognizable\"]\n",
      "Any[\"units\", \"memory\", \"unit\", \"patterns\", \"number\", \"pattern\", \"representation\", \"region\", \"joint\", \"active\"]\n",
      "[\"gos\", \"nijmegen\", \"psycholinguistik\"]\n",
      "Any[\"data\", \"problem\", \"given\", \"one\", \"function\", \"variance\", \"paper\", \"number\", \"mixture\", \"set\"]\n",
      "[\"bahram\", \"afscsprojectconnectbench\", \"maxmachine\"]\n",
      "Any[\"cell\", \"analog\", \"figure\", \"chip\", \"neuron\", \"properties\", \"synaptic\", \"neural\", \"new\", \"neurons\"]\n",
      "[\"ujtubt\", \"literaturei\", \"feedback_neural\"]\n",
      "Any[\"network\", \"output\", \"neural\", \"input\", \"networks\", \"figure\", \"control\", \"architecture\", \"feedback\", \"nonlinear\"]\n",
      "[\"afscsprojectconnectbench\", \"underfitting\", \"psychophysicallymotivated\"]\n",
      "Any[\"training\", \"algorithm\", \"set\", \"class\", \"speech\", \"model\", \"neural\", \"vectors\", \"network\", \"classification\"]\n",
      "[\"afscsprojectconnectbench\", \"ftpcscmu\", \"cambrdge\"]\n",
      "Any[\"networks\", \"neural\", \"size\", \"one\", \"results\", \"parameters\", \"functions\", \"since\", \"form\", \"matrix\"]\n",
      "[\"maxmachine\", \"yasercaltechedu\", \"caruanacscmuedu\"]\n",
      "Any[\"distance\", \"tangent\", \"information\", \"weight\", \"net\", \"used\", \"use\", \"function\", \"transformation\", \"inputs\"]\n",
      "[\"wnt\", \"elimination\", \"rethworcementlearmng\"]\n",
      "Any[\"error\", \"generalization\", \"learning\", \"space\", \"linear\", \"training\", \"teacher\", \"function\", \"optimal\", \"distribution\"]\n",
      "[\"openversusclosed\", \"psycholrev\", \"expettation\"]\n",
      "Any[\"auditory\", \"time\", \"units\", \"weights\", \"network\", \"system\", \"layer\", \"used\", \"two\", \"signal\"]\n",
      "[\"sweeps\", \"contractionbased\", \"perilous\"]\n",
      "Any[\"state\", \"algorithm\", \"states\", \"algorithms\", \"convergence\", \"function\", \"action\", \"policy\", \"markov\", \"value\"]\n",
      "[\"maplike\", \"sardines\", \"scaleup\"]\n",
      "Any[\"input\", \"map\", \"sequence\", \"context\", \"sequences\", \"units\", \"system\", \"feature\", \"representation\", \"word\"]\n",
      "[\"kaufinann\", \"resistant\", \"consolidated\"]\n",
      "Any[\"field\", \"learning\", \"visual\", \"motion\", \"motor\", \"model\", \"two\", \"direction\", \"sensory\", \"point\"]\n",
      "[\"openversusclosed\", \"afscsprojectconnectbench\", \"neurallnfonnation\"]\n",
      "Any[\"figure\", \"performance\", \"features\", \"unit\", \"road\", \"information\", \"representations\", \"right\", \"level\", \"new\"]\n",
      "[\"odorant\", \"biochemistry\", \"ofreceptor\"]\n",
      "Any[\"neurons\", \"computational\", \"model\", \"response\", \"simulations\", \"neuron\", \"simulation\", \"number\", \"stem\", \"analysis\"]\n",
      "[\"mccallumccsrochesteredu\", \"utomatic\", \"arcidtectures\"]\n",
      "Any[\"learning\", \"time\", \"probability\", \"training\", \"machine\", \"error\", \"first\", \"series\", \"order\", \"reinforcement\"]\n"
     ]
    }
   ],
   "source": [
    "# For comparing top 50 words of topic distributions\n",
    "for (pos, i) in enumerate(topics)\n",
    "    println([l[1] for l in top_3_labels[pos]])\n",
    "    println(i[1:10])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word count in topic labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278-element Array{Pair{Any,Any},1}:\n",
       "           \"mlp\" => 21\n",
       "          \"risk\" => 15\n",
       "    \"confidence\" => 14\n",
       "     \"bootstrap\" => 12\n",
       "           \"vol\" => 11\n",
       "       \"surgery\" => 9\n",
       "    \"operations\" => 8\n",
       "     \"mortality\" => 8\n",
       "      \"networks\" => 8\n",
       "       \"failure\" => 7\n",
       " \"complications\" => 7\n",
       "       \"history\" => 7\n",
       "         \"renal\" => 7\n",
       "                 ⋮\n",
       "       \"factors\" => 1\n",
       "  \"interactions\" => 1\n",
       "       \"strokes\" => 1\n",
       "     \"committee\" => 1\n",
       "        \"number\" => 1\n",
       "      \"maintain\" => 1\n",
       "         \"block\" => 1\n",
       "       \"reflect\" => 1\n",
       "       \"summary\" => 1\n",
       "       \"average\" => 1\n",
       "      \"spending\" => 1\n",
       "   \"performance\" => 1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort(collect(labels_freq[\"coronary_artery_bypass\"]), by=x->x[2], rev=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 15739 entries:\n",
       "  \"oblique\"     => Dict{Any,Any}(\"points\"=>5,\"jlkl\"=>2,\"translation\"=>2,\"sekule…\n",
       "  \"dev\"         => Dict{Any,Any}(\"fpxsftvg\"=>1,\"fprr\"=>1,\"neurophysiol\"=>1,\"res…\n",
       "  \"cambrdge\"    => Dict{Any,Any}(\"proceedings\"=>1,\"learningfrom\"=>1,\"tesauro\"=>…\n",
       "  \"yjk\"         => Dict{Any,Any}(\"corresponding\"=>1,\"rotation\"=>1,\"points\"=>2,\"…\n",
       "  \"null\"        => Dict{Any,Any}(\"regions\"=>2,\"uext\"=>1,\"oblique\"=>1,\"excitatio…\n",
       "  \"inflowbased\" => Dict{Any,Any}(\"choices\"=>1,\"accommodate\"=>1,\"optimal\"=>1,\"in…\n",
       "  \"ztt\"         => Dict{Any,Any}(\"qlearning\"=>1,\"presented\"=>2,\"directly\"=>1,\"m…\n",
       "  \"iaan\"        => Dict{Any,Any}(\"want\"=>2,\"elog\"=>2,\"emax\"=>2,\"holds\"=>3,\"fini…\n",
       "  \"subfeature\"  => Dict{Any,Any}(\"tasks\"=>1,\"due\"=>1,\"indicate\"=>1,\"relevant\"=>…\n",
       "  \"rises\"       => Dict{Any,Any}(\"constant\"=>3,\"functional\"=>1,\"los\"=>2,\"equal\"…\n",
       "  \"hampshire\"   => Dict{Any,Any}(\"constant\"=>1,\"action\"=>1,\"equal\"=>1,\"data\"=>1…\n",
       "  \"dzfk\"        => Dict{Any,Any}(\"fpxsftvg\"=>1,\"dem\"=>1,\"fprr\"=>1,\"kxt\"=>1,\"fqm…\n",
       "  \"vapnik\"      => Dict{Any,Any}(\"functional\"=>1,\"regions\"=>2,\"parallel\"=>1,\"in…\n",
       "  \"progression\" => Dict{Any,Any}(\"functional\"=>1,\"damage\"=>1,\"gradual\"=>1,\"lesi…\n",
       "  \"neumann\"     => Dict{Any,Any}(\"extraction\"=>1,\"singlelayer\"=>1,\"optimal\"=>1,…\n",
       "  \"fram\"        => Dict{Any,Any}(\"variance\"=>2,\"decisions\"=>2,\"gain\"=>1,\"expert…\n",
       "  \"gathered\"    => Dict{Any,Any}(\"satellite\"=>1,\"approximates\"=>1,\"planetary\"=>…\n",
       "  \"eeitutery\"   => Dict{Any,Any}(\"pre\"=>1,\"pointsets\"=>2,\"objects\"=>3,\"appropri…\n",
       "  \"arborize\"    => Dict{Any,Any}(\"striking\"=>1,\"connections\"=>1,\"selectively\"=>…\n",
       "  \"november\"    => Dict{Any,Any}(\"generalization\"=>1,\"amir\"=>1,\"university\"=>1,…\n",
       "  \"stress\"      => Dict{Any,Any}(\"tasks\"=>5,\"introduced\"=>1,\"optimal\"=>1,\"would…\n",
       "  \"zqm\"         => Dict{Any,Any}(\"aefoc\"=>1,\"vwd\"=>1,\"dmhyrtsmfys\"=>1,\"gxwky\"=>…\n",
       "  \"rectified\"   => Dict{Any,Any}(\"excitation\"=>1,\"nadel\"=>1,\"stable\"=>1,\"square…\n",
       "  \"obey\"        => Dict{Any,Any}(\"whereas\"=>1,\"known\"=>1,\"firstorder\"=>1,\"simpl…\n",
       "  \"methods\"     => Dict{Any,Any}(\"rumeihart\"=>1,\"perturbations\"=>1,\"newly\"=>1,\"…\n",
       "  ⋮             => ⋮"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 14707 entries:\n",
       "  \"oblique\"     => 7247\n",
       "  \"dev\"         => 16\n",
       "  \"cambrdge\"    => 3145\n",
       "  \"yjk\"         => 7246\n",
       "  \"null\"        => 1728\n",
       "  \"inflowbased\" => 1831\n",
       "  \"ztt\"         => 4061\n",
       "  \"iaan\"        => 6949\n",
       "  \"subfeature\"  => 10738\n",
       "  \"rises\"       => 6074\n",
       "  \"hampshire\"   => 11903\n",
       "  \"dzfk\"        => 8\n",
       "  \"vapnik\"      => 3387\n",
       "  \"progression\" => 8512\n",
       "  \"neumann\"     => 5360\n",
       "  \"fram\"        => 10918\n",
       "  \"gathered\"    => 7052\n",
       "  \"eeitutery\"   => 7290\n",
       "  \"arborize\"    => 10152\n",
       "  \"november\"    => 6778\n",
       "  \"stress\"      => 5963\n",
       "  \"zqm\"         => 8291\n",
       "  \"rectified\"   => 6644\n",
       "  \"obey\"        => 2264\n",
       "  \"methods\"     => 818\n",
       "  ⋮             => ⋮"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_output\n",
      "coronary_artery_bypass\n",
      "neural_information_processing_systems\n",
      "i_i_i\n",
      "using_neural_networks\n",
      "as_shown_in_figure\n",
      "m__m\n",
      "can_be_obtained\n",
      "networks_of_spiking_neurons\n",
      "we_assume_that\n",
      "i__i_\n",
      "this_paper_we\n",
      "this_can_be\n",
      "can_be_derived\n",
      "learning_from_examples\n",
      "it_is_possible\n",
      "editors_advances_in_neural_information\n",
      "i_i_i_i\n",
      "cambridge_ma\n",
      "office_of_naval_research\n",
      "city_block_length\n",
      "can_be_viewed_as\n",
      "radial_basis_function\n",
      "where_n\n",
      "teacher_space_entropy\n",
      "we_then\n",
      "output_is\n",
      "is_defined_as\n",
      "that_can_be\n",
      "we_find_that\n",
      "et_al_eds\n",
      "san_mateo_ca\n",
      "can_be_used\n",
      "modified_actorcritic_algorithm\n",
      "hierarchical_mixtures_of_experts\n",
      "which_can_be\n",
      "training_algorithms\n",
      "it_is_not\n",
      "et_al\n",
      "all_other\n",
      "processing_systems_san_mateo\n",
      "network_is\n",
      "processing_systems_morgan_kaufmann\n",
      "will_not_be\n",
      "m_is\n",
      "pittsburgh_pa\n",
      "where_is\n",
      "elastic_input_field\n",
      "eds_advances_in_neural_information\n",
      "it_can_be_shown\n",
      "l_d\n",
      "it_does_not\n",
      "can_be_found\n",
      "here_is\n",
      "carnegie_mellon_university\n",
      "way_that\n",
      "it_may_be\n",
      "information_processing_systems\n",
      "terrence_j_sejnowski\n",
      "there_is_no\n",
      "receiver_operating_characteristic\n",
      "this_paper_is\n",
      "hidden_markov_models\n",
      "i__i\n",
      "artificial_neural_networks\n",
      "be_shown_that\n",
      "we_first\n",
      "can_be_done\n",
      "chaotic_time_series\n",
      "can_be_interpreted_as\n",
      "time_series_prediction\n",
      "can_be_seen\n",
      "abstract_this_paper\n",
      "this_is_not\n",
      "advances_in_neural_information_processing\n",
      "san_mateo_ca_morgan\n",
      "this_paper_presents\n",
      "c__c_\n",
      "we_see_that\n",
      "department_of_computer_science\n",
      "principal_component_analysis\n",
      "single_transistor\n",
      "is_shown_in_figure\n",
      "have_the_same\n",
      "morgan_kaufmann_publishers\n",
      "neural_network_control\n",
      "soft_state_aggregation\n",
      "there_are_two\n",
      "probability_one\n",
      "michael_i_jordan\n",
      "as_long_as\n",
      "ca_morgan_kaufmann\n",
      "instancebased_state_identification\n",
      "we_show_that\n",
      "x_is\n",
      "daniel_m_wolpert\n",
      "have_shown_that\n",
      "is_that\n",
      "can_be_achieved\n",
      "it_has_been\n",
      "as_well_as\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for (phrase, score) in phrase_model_bigram.find_phrases(bigrams_docs)\n",
    "    println(phrase)\n",
    "    s+=1\n",
    "end\n",
    "println(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech related random commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17802-element Array{Tuple{String,String},1}:\n",
       " (\"A\", \"DT\")\n",
       " (\"n\", \"JJ\")\n",
       " (\" \", \"NN\")\n",
       " (\"A\", \"NNP\")\n",
       " (\"l\", \"NN\")\n",
       " (\"t\", \"NN\")\n",
       " (\"e\", \"NN\")\n",
       " (\"r\", \"NN\")\n",
       " (\"n\", \"IN\")\n",
       " (\"a\", \"DT\")\n",
       " (\"t\", \"NN\")\n",
       " (\"i\", \"NN\")\n",
       " (\"v\", \"VBP\")\n",
       " ⋮\n",
       " (\"p\", \"JJ\")\n",
       " (\"u\", \"JJ\")\n",
       " (\"t\", \"NN\")\n",
       " (\"a\", \"DT\")\n",
       " (\"t\", \"NN\")\n",
       " (\"i\", \"NN\")\n",
       " (\"o\", \"VBP\")\n",
       " (\"n\", \"NN\")\n",
       " (\".\", \".\")\n",
       " (\"\\n\", \"CC\")\n",
       " (\"\\n\", \"JJ\")\n",
       " (\"\\f\", \"NN\")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= nltk.pos_tag(docs[7143])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: a not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: a not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at ./In[3]:1",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091",
      " [3] execute_code(::String, ::String) at /Users/khan/.julia/packages/IJulia/a1SNk/src/execute_request.jl:27",
      " [4] execute_request(::ZMQ.Socket, ::IJulia.Msg) at /Users/khan/.julia/packages/IJulia/a1SNk/src/execute_request.jl:86",
      " [5] #invokelatest#1 at ./essentials.jl:710 [inlined]",
      " [6] invokelatest at ./essentials.jl:709 [inlined]",
      " [7] eventloop(::ZMQ.Socket) at /Users/khan/.julia/packages/IJulia/a1SNk/src/eventloop.jl:8",
      " [8] (::IJulia.var\"#15#18\")() at ./task.jl:356"
     ]
    }
   ],
   "source": [
    "for i in a\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <module 'nltk' from '/Users/khan/.julia/conda/3/lib/python3.8/site-packages/nltk/__init__.py'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "nltk = pyimport(\"nltk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <WordNetLemmatizer>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Word\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.lemmatize(\"Word\", pos=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: nltk not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: nltk not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[8]:2",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091",
      " [3] execute_code(::String, ::String) at /Users/khan/.julia/packages/IJulia/a1SNk/src/execute_request.jl:27",
      " [4] execute_request(::ZMQ.Socket, ::IJulia.Msg) at /Users/khan/.julia/packages/IJulia/a1SNk/src/execute_request.jl:86",
      " [5] #invokelatest#1 at ./essentials.jl:710 [inlined]",
      " [6] invokelatest at ./essentials.jl:709 [inlined]",
      " [7] eventloop(::ZMQ.Socket) at /Users/khan/.julia/packages/IJulia/a1SNk/src/eventloop.jl:8",
      " [8] (::IJulia.var\"#15#18\")() at ./task.jl:356"
     ]
    }
   ],
   "source": [
    "using DataStructures\n",
    "wn = nltk.corpus.wordnet\n",
    "t_map = Dict('J' => wn.ADJ,'V' => wn.VERB,'R' => wn.ADV)\n",
    "\n",
    "tag_map = DefaultDict(wn.NOUN, t_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_map['Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Char,Int64} with 2 entries:\n",
       "  'a' => 1\n",
       "  'b' => 2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = DefaultDict(1) \n",
    "d = Dict('a'=>1, 'b'=>2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DefaultDict{Char,Int64,Int64} with 2 entries:\n",
       "  'a' => 1\n",
       "  'b' => 2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = DefaultDict(0, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd['A']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
