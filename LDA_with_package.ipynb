{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Activating\u001b[22m\u001b[39m environment at `~/Documents/Thesis/Git_Main/julia_bayes/TopicModels/Project.toml`\n",
      "┌ Info: Precompiling TopicModels [cfcb1801-bb54-4f1b-8249-336c042d2c46]\n",
      "└ @ Base loading.jl:1278\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "using StatsBase\n",
    "Pkg.activate(\"TopicModels\")\n",
    "import TopicModels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Run on Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = TopicModels.documentset_readData(\"news-en.txt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordPrior = TopicModels.Dirichlet(12, 0.01)\n",
    "M = 3\n",
    "alpha = [0.01 for i in 1:M];\n",
    "topicPrior = TopicModels.Dirichlet(alpha);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = TopicModels.LDA(topicPrior, wordPrior);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = TopicModels.lda_sample(corpus.documents, lda);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st topic and top 5 words along with vocab proportion\n",
    "words, proportions = TopicModels.lda_topicN(3, 4, corpus, lda);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"medal\", \"runner\", \"era\", \"culture\"]\n",
      "[0.39258, 0.19727, 0.19727, 0.19727]\n"
     ]
    }
   ],
   "source": [
    "println(words)\n",
    "println(proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA on NIPS papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing papers and few preprocessing steps\n",
    "papers = CSV.read(\"papers.csv\", DataFrame);\n",
    "papers_txt = papers.paper_text;\n",
    "stopwords = []\n",
    "specialchars = ['!', '”', '#', '$', '%', '&', '’', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '>', '=', '@', '?', '[', ']', '^', '_', '{', '}', '|', '~']\n",
    "open(\"stopwords.txt\") do file\n",
    "    for word in eachline(file)\n",
    "        push!(stopwords, word)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function clean_words(docs::Array, stopwords::Array, specialchars::Array) \n",
    "    #Remove stop words, special characters, numbers, and 2_or_less char words\n",
    "    new_docs = []\n",
    "    for line in docs\n",
    "        doc = split(line)\n",
    "        temp = []\n",
    "        for word in doc\n",
    "            word = lowercase(replace.(word, specialchars => \"\"))\n",
    "            if !(word in stopwords) \n",
    "                if length(word) > 2 && tryparse(Float64, word) == nothing\n",
    "                    push!(temp, word)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        push!(new_docs, temp)\n",
    "    end\n",
    "    return new_docs\n",
    "end\n",
    "\n",
    "papers_txt = clean_words(papers_txt, stopwords, specialchars);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_txt = papers_txt[6242:7241]\n",
    "size(papers_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108086"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = TopicModels.documentset_readData(papers_txt);\n",
    "corpus.vocab_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordPrior = TopicModels.Dirichlet(corpus.vocab_count, 0.01)\n",
    "M = 20 # Number of topics\n",
    "alpha = [0.01 for i in 1:M];\n",
    "topicPrior = TopicModels.Dirichlet(alpha);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = TopicModels.LDA(topicPrior, wordPrior);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopicModels.lda_sample(corpus.documents, lda);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"matrix\", \"sparse\", \"matrices\", \"time\", \"rank\", \"error\", \"problem\", \"linear\", \"algorithm\", \"tensor\"]\n",
      "Any[\"adversarial\", \"training\", \"generative\", \"data\", \"gan\", \"samples\", \"distribution\", \"generator\", \"discriminator\", \"objective\"]\n",
      "Any[\"policy\", \"learning\", \"state\", \"reinforcement\", \"reward\", \"action\", \"agent\", \"policies\", \"value\", \"using\"]\n",
      "Any[\"model\", \"models\", \"data\", \"used\", \"using\", \"speech\", \"figure\", \"prediction\", \"modeling\", \"neural\"]\n",
      "Any[\"distribution\", \"inference\", \"model\", \"data\", \"models\", \"log\", \"gaussian\", \"posterior\", \"variational\", \"bayesian\"]\n",
      "Any[\"time\", \"system\", \"control\", \"noise\", \"figure\", \"model\", \"state\", \"process\", \"memory\", \"point\"]\n",
      "Any[\"graph\", \"algorithm\", \"clustering\", \"nodes\", \"node\", \"set\", \"algorithms\", \"cluster\", \"graphs\", \"problem\"]\n",
      "Any[\"learning\", \"algorithm\", \"algorithms\", \"loss\", \"time\", \"online\", \"machine\", \"problem\", \"cost\", \"pages\"]\n",
      "Any[\"set\", \"algorithm\", \"local\", \"one\", \"data\", \"used\", \"new\", \"two\", \"structure\", \"figure\"]\n",
      "Any[\"learning\", \"deep\", \"image\", \"training\", \"images\", \"networks\", \"neural\", \"loss\", \"dataset\", \"classification\"]\n",
      "Any[\"data\", \"rules\", \"vector\", \"number\", \"using\", \"rule\", \"set\", \"two\", \"information\", \"similarity\"]\n",
      "Any[\"neurons\", \"activity\", \"neural\", \"model\", \"cells\", \"cell\", \"figure\", \"neuron\", \"visual\", \"brain\"]\n",
      "Any[\"network\", \"networks\", \"neural\", \"training\", \"learning\", \"error\", \"layer\", \"output\", \"input\", \"units\"]\n",
      "Any[\"gradient\", \"optimization\", \"convergence\", \"convex\", \"algorithm\", \"stochastic\", \"descent\", \"methods\", \"method\", \"rate\"]\n",
      "Any[\"bound\", \"regret\", \"bounds\", \"algorithm\", \"theorem\", \"probability\", \"log\", \"distribution\", \"complexity\", \"lemma\"]\n",
      "Any[\"function\", \"functions\", \"set\", \"case\", \"one\", \"problem\", \"given\", \"optimal\", \"let\", \"consider\"]\n",
      "Any[\"kernel\", \"data\", \"features\", \"feature\", \"learning\", \"methods\", \"space\", \"points\", \"distance\", \"using\"]\n",
      "Any[\"games\", \"game\", \"player\", \"players\", \"communication\", \"revenue\", \"agents\", \"strategy\", \"price\", \"equilibrium\"]\n",
      "Any[\"object\", \"attention\", \"image\", \"network\", \"objects\", \"task\", \"neural\", \"visual\", \"convolutional\", \"features\"]\n",
      "Any[\"data\", \"model\", \"regression\", \"risk\", \"causal\", \"classification\", \"classifier\", \"set\", \"selection\", \"using\"]\n"
     ]
    }
   ],
   "source": [
    "top_N = 10\n",
    "for i in 1:M\n",
    "    #println(\"Topic $i top $top_N words:\")\n",
    "    words, proportions = TopicModels.lda_topicN(i, top_N, corpus, lda);\n",
    "    println(words)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopicModels.Dirichlet(108086, [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01  …  0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01], 1080.8500001000002)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TopicModels.lda_removeWord(\"model\", 20, corpus, lda);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopicModels.lda_gibbsSampling(corpus.documents, 20, lda);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"matrix\", \"sparse\", \"matrices\", \"rank\", \"algorithm\", \"time\", \"estimation\", \"norm\", \"tensor\", \"problem\"]\n",
      "Any[\"adversarial\", \"training\", \"generative\", \"data\", \"gan\", \"samples\", \"distribution\", \"generator\", \"discriminator\", \"objective\"]\n",
      "Any[\"policy\", \"learning\", \"state\", \"reward\", \"reinforcement\", \"action\", \"agent\", \"policies\", \"using\", \"value\"]\n",
      "Any[\"model\", \"models\", \"data\", \"using\", \"speech\", \"neural\", \"modeling\", \"figure\", \"network\", \"used\"]\n",
      "Any[\"model\", \"distribution\", \"inference\", \"data\", \"models\", \"log\", \"gaussian\", \"posterior\", \"variational\", \"bayesian\"]\n",
      "Any[\"time\", \"model\", \"system\", \"noise\", \"state\", \"control\", \"figure\", \"process\", \"memory\", \"systems\"]\n",
      "Any[\"graph\", \"algorithm\", \"clustering\", \"nodes\", \"node\", \"set\", \"algorithms\", \"problem\", \"cluster\", \"graphs\"]\n",
      "Any[\"learning\", \"algorithm\", \"algorithms\", \"loss\", \"time\", \"online\", \"problem\", \"machine\", \"cost\", \"pages\"]\n",
      "Any[\"set\", \"algorithm\", \"local\", \"two\", \"data\", \"figure\", \"one\", \"used\", \"new\", \"node\"]\n",
      "Any[\"learning\", \"deep\", \"training\", \"image\", \"images\", \"networks\", \"neural\", \"network\", \"loss\", \"classification\"]\n",
      "Any[\"data\", \"rules\", \"number\", \"rule\", \"vector\", \"using\", \"probability\", \"similarity\", \"two\", \"quantization\"]\n",
      "Any[\"neurons\", \"activity\", \"neural\", \"cells\", \"neuron\", \"visual\", \"cell\", \"figure\", \"input\", \"information\"]\n",
      "Any[\"network\", \"networks\", \"neural\", \"training\", \"learning\", \"error\", \"output\", \"layer\", \"input\", \"weights\"]\n",
      "Any[\"gradient\", \"optimization\", \"convergence\", \"convex\", \"algorithm\", \"stochastic\", \"descent\", \"methods\", \"method\", \"rate\"]\n",
      "Any[\"bound\", \"regret\", \"bounds\", \"theorem\", \"algorithm\", \"log\", \"probability\", \"distribution\", \"complexity\", \"lemma\"]\n",
      "Any[\"function\", \"functions\", \"one\", \"set\", \"case\", \"given\", \"optimal\", \"problem\", \"consider\", \"also\"]\n",
      "Any[\"kernel\", \"data\", \"features\", \"learning\", \"feature\", \"methods\", \"space\", \"points\", \"distance\", \"regression\"]\n",
      "Any[\"games\", \"game\", \"player\", \"privacy\", \"players\", \"communication\", \"revenue\", \"strategy\", \"agents\", \"price\"]\n",
      "Any[\"object\", \"attention\", \"image\", \"neural\", \"objects\", \"network\", \"visual\", \"layer\", \"language\", \"convolutional\"]\n",
      "Any[\"data\", \"regression\", \"causal\", \"risk\", \"classifier\", \"classification\", \"selection\", \"using\", \"set\", \"different\"]\n"
     ]
    }
   ],
   "source": [
    "top_N = 10\n",
    "for i in 1:M\n",
    "    #println(\"Topic $i top $top_N words:\")\n",
    "    words, proportions = TopicModels.lda_topicN(i, top_N, corpus, lda);\n",
    "    println(words)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Human in the Loop Topic Modeling with APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = TopicModels.preprocess(\"papers.csv\", 1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = TopicModels.train(corpus, 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"tree\", \"causal\", \"graph\", \"model\", \"structure\"]\n",
      "[0.01491, 0.01017, 0.00972, 0.0091, 0.00861]\n",
      "----------------------\n",
      "Any[\"distributed\", \"communication\", \"parallel\", \"speech\", \"system\"]\n",
      "[0.01602, 0.01339, 0.00854, 0.00807, 0.00761]\n",
      "----------------------\n",
      "Any[\"model\", \"learning\", \"models\", \"neural\", \"classification\"]\n",
      "[0.01847, 0.01383, 0.01044, 0.00929, 0.00909]\n",
      "----------------------\n",
      "Any[\"network\", \"networks\", \"neural\", \"learning\", \"training\"]\n",
      "[0.04085, 0.03544, 0.03032, 0.01448, 0.01397]\n",
      "----------------------\n",
      "Any[\"learning\", \"task\", \"tasks\", \"training\", \"information\"]\n",
      "[0.02579, 0.01454, 0.01381, 0.0123, 0.00985]\n",
      "----------------------\n",
      "Any[\"inference\", \"variational\", \"generative\", \"data\", \"distribution\"]\n",
      "[0.01724, 0.01572, 0.01421, 0.01284, 0.01253]\n",
      "----------------------\n",
      "Any[\"time\", \"model\", \"state\", \"system\", \"dynamics\"]\n",
      "[0.01939, 0.01934, 0.01736, 0.01468, 0.01301]\n",
      "----------------------\n",
      "Any[\"training\", \"set\", \"error\", \"input\", \"using\"]\n",
      "[0.01394, 0.01296, 0.01295, 0.00882, 0.00868]\n",
      "----------------------\n",
      "Any[\"clustering\", \"algorithm\", \"distance\", \"points\", \"data\"]\n",
      "[0.02044, 0.01859, 0.01687, 0.01458, 0.01408]\n",
      "----------------------\n",
      "Any[\"distribution\", \"model\", \"probability\", \"estimation\", \"function\"]\n",
      "[0.01858, 0.01387, 0.0101, 0.00976, 0.00973]\n",
      "----------------------\n",
      "Any[\"kernel\", \"data\", \"learning\", \"regression\", \"features\"]\n",
      "[0.02902, 0.01728, 0.01621, 0.01559, 0.01468]\n",
      "----------------------\n",
      "Any[\"neurons\", \"input\", \"neuron\", \"activity\", \"cells\"]\n",
      "[0.01417, 0.0093, 0.00768, 0.00758, 0.00692]\n",
      "----------------------\n",
      "Any[\"gradient\", \"optimization\", \"algorithm\", \"convergence\", \"convex\"]\n",
      "[0.01748, 0.01693, 0.01503, 0.01457, 0.01288]\n",
      "----------------------\n",
      "Any[\"graph\", \"set\", \"nodes\", \"algorithm\", \"problem\"]\n",
      "[0.01545, 0.01241, 0.01228, 0.01084, 0.01078]\n",
      "----------------------\n",
      "Any[\"policy\", \"learning\", \"state\", \"reward\", \"reinforcement\"]\n",
      "[0.0275, 0.0186, 0.01483, 0.0144, 0.01239]\n",
      "----------------------\n",
      "Any[\"algorithm\", \"learning\", \"bound\", \"theorem\", \"bounds\"]\n",
      "[0.01773, 0.01452, 0.01391, 0.0116, 0.00954]\n",
      "----------------------\n",
      "Any[\"image\", \"images\", \"convolutional\", \"network\", \"object\"]\n",
      "[0.03002, 0.01935, 0.01151, 0.01125, 0.0112]\n",
      "----------------------\n",
      "Any[\"data\", \"performance\", \"number\", \"using\", \"sampling\"]\n",
      "[0.01895, 0.00975, 0.00902, 0.0063, 0.00627]\n",
      "----------------------\n",
      "Any[\"data\", \"neural\", \"analysis\", \"time\", \"vol\"]\n",
      "[0.01189, 0.01146, 0.01046, 0.00957, 0.00879]\n",
      "----------------------\n",
      "Any[\"matrix\", \"theorem\", \"sparse\", \"error\", \"log\"]\n",
      "[0.03155, 0.0083, 0.00774, 0.00711, 0.00709]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "TopicModels.show_topics(corpus, lda, 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopicModels.apply_refinement(corpus, lda, \"remove\", \"model\", 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"tree\", \"causal\", \"structure\", \"learning\", \"node\"]\n",
      "[0.01452, 0.01132, 0.008, 0.00684, 0.00671]\n",
      "----------------------\n",
      "Any[\"distributed\", \"communication\", \"time\", \"parallel\", \"computation\"]\n",
      "[0.0162, 0.01345, 0.0094, 0.00743, 0.00727]\n",
      "----------------------\n",
      "Any[\"model\", \"learning\", \"models\", \"neural\", \"classification\"]\n",
      "[0.01554, 0.0112, 0.01058, 0.00966, 0.00956]\n",
      "----------------------\n",
      "Any[\"network\", \"networks\", \"neural\", \"learning\", \"layer\"]\n",
      "[0.04174, 0.03607, 0.03141, 0.01505, 0.01477]\n",
      "----------------------\n",
      "Any[\"learning\", \"training\", \"task\", \"tasks\", \"model\"]\n",
      "[0.02812, 0.01439, 0.01394, 0.01243, 0.01097]\n",
      "----------------------\n",
      "Any[\"inference\", \"variational\", \"generative\", \"distribution\", \"latent\"]\n",
      "[0.01735, 0.01547, 0.01443, 0.01311, 0.01281]\n",
      "----------------------\n",
      "Any[\"model\", \"time\", \"state\", \"system\", \"dynamics\"]\n",
      "[0.0187, 0.01858, 0.01801, 0.01476, 0.01331]\n",
      "----------------------\n",
      "Any[\"training\", \"set\", \"error\", \"input\", \"one\"]\n",
      "[0.01268, 0.01188, 0.0105, 0.01001, 0.00951]\n",
      "----------------------\n",
      "Any[\"clustering\", \"distance\", \"algorithm\", \"data\", \"points\"]\n",
      "[0.02317, 0.01888, 0.01864, 0.01498, 0.01407]\n",
      "----------------------\n",
      "Any[\"distribution\", \"model\", \"function\", \"probability\", \"estimation\"]\n",
      "[0.01653, 0.0155, 0.01021, 0.01003, 0.00952]\n",
      "----------------------\n",
      "Any[\"kernel\", \"regression\", \"features\", \"learning\", \"data\"]\n",
      "[0.03061, 0.01716, 0.0154, 0.0147, 0.0142]\n",
      "----------------------\n",
      "Any[\"neurons\", \"input\", \"activity\", \"cells\", \"neuron\"]\n",
      "[0.01353, 0.00854, 0.00752, 0.0075, 0.0074]\n",
      "----------------------\n",
      "Any[\"gradient\", \"optimization\", \"algorithm\", \"convergence\", \"convex\"]\n",
      "[0.01794, 0.01779, 0.0145, 0.01442, 0.01306]\n",
      "----------------------\n",
      "Any[\"graph\", \"nodes\", \"set\", \"node\", \"algorithm\"]\n",
      "[0.01988, 0.01391, 0.01282, 0.01099, 0.01046]\n",
      "----------------------\n",
      "Any[\"policy\", \"learning\", \"state\", \"reward\", \"reinforcement\"]\n",
      "[0.02783, 0.01728, 0.01522, 0.01413, 0.01248]\n",
      "----------------------\n",
      "Any[\"algorithm\", \"learning\", \"bound\", \"theorem\", \"regret\"]\n",
      "[0.01806, 0.01544, 0.01291, 0.01159, 0.00953]\n",
      "----------------------\n",
      "Any[\"image\", \"images\", \"convolutional\", \"object\", \"network\"]\n",
      "[0.03118, 0.01853, 0.01224, 0.01201, 0.01174]\n",
      "----------------------\n",
      "Any[\"data\", \"performance\", \"number\", \"model\", \"set\"]\n",
      "[0.01672, 0.0099, 0.00974, 0.0071, 0.00673]\n",
      "----------------------\n",
      "Any[\"data\", \"time\", \"analysis\", \"neural\", \"vol\"]\n",
      "[0.01289, 0.01076, 0.01029, 0.00946, 0.00916]\n",
      "----------------------\n",
      "Any[\"matrix\", \"theorem\", \"sparse\", \"log\", \"matrices\"]\n",
      "[0.03183, 0.00884, 0.00768, 0.00735, 0.00728]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "TopicModels.show_topics(corpus, lda, 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopicModels.apply_refinement(corpus, lda, \"add\", \"node\", 2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"node\", \"tree\", \"causal\", \"variables\", \"structure\"]\n",
      "[0.01417, 0.01356, 0.01129, 0.00682, 0.00682]\n",
      "----------------------\n",
      "Any[\"node\", \"distributed\", \"communication\", \"parallel\", \"time\"]\n",
      "[0.03395, 0.01575, 0.01249, 0.00748, 0.00709]\n",
      "----------------------\n",
      "Any[\"model\", \"models\", \"learning\", \"attention\", \"classification\"]\n",
      "[0.01731, 0.01129, 0.01089, 0.00975, 0.00936]\n",
      "----------------------\n",
      "Any[\"network\", \"networks\", \"neural\", \"learning\", \"training\"]\n",
      "[0.04226, 0.03604, 0.03199, 0.01466, 0.01423]\n",
      "----------------------\n",
      "Any[\"learning\", \"training\", \"task\", \"tasks\", \"model\"]\n",
      "[0.02811, 0.01529, 0.01407, 0.01217, 0.00995]\n",
      "----------------------\n",
      "Any[\"inference\", \"variational\", \"generative\", \"distribution\", \"latent\"]\n",
      "[0.01722, 0.01538, 0.0139, 0.01368, 0.01257]\n",
      "----------------------\n",
      "Any[\"time\", \"state\", \"model\", \"system\", \"dynamics\"]\n",
      "[0.01847, 0.01811, 0.01695, 0.01467, 0.01329]\n",
      "----------------------\n",
      "Any[\"training\", \"set\", \"input\", \"error\", \"one\"]\n",
      "[0.01276, 0.01168, 0.01059, 0.01006, 0.00927]\n",
      "----------------------\n",
      "Any[\"clustering\", \"distance\", \"algorithm\", \"data\", \"points\"]\n",
      "[0.0238, 0.01771, 0.01703, 0.01557, 0.01451]\n",
      "----------------------\n",
      "Any[\"distribution\", \"model\", \"probability\", \"function\", \"estimation\"]\n",
      "[0.01535, 0.01473, 0.01043, 0.01041, 0.00896]\n",
      "----------------------\n",
      "Any[\"kernel\", \"regression\", \"learning\", \"features\", \"data\"]\n",
      "[0.03202, 0.01839, 0.01642, 0.01449, 0.01314]\n",
      "----------------------\n",
      "Any[\"neurons\", \"input\", \"activity\", \"cells\", \"neuron\"]\n",
      "[0.01358, 0.00869, 0.00799, 0.00751, 0.00702]\n",
      "----------------------\n",
      "Any[\"optimization\", \"gradient\", \"algorithm\", \"convergence\", \"convex\"]\n",
      "[0.01815, 0.01793, 0.01526, 0.01435, 0.01334]\n",
      "----------------------\n",
      "Any[\"graph\", \"set\", \"nodes\", \"algorithm\", \"function\"]\n",
      "[0.01992, 0.01334, 0.01193, 0.01119, 0.00967]\n",
      "----------------------\n",
      "Any[\"policy\", \"learning\", \"state\", \"reward\", \"reinforcement\"]\n",
      "[0.02839, 0.01855, 0.01558, 0.01436, 0.01278]\n",
      "----------------------\n",
      "Any[\"algorithm\", \"learning\", \"bound\", \"theorem\", \"regret\"]\n",
      "[0.01904, 0.01497, 0.01323, 0.01191, 0.00985]\n",
      "----------------------\n",
      "Any[\"image\", \"images\", \"convolutional\", \"object\", \"network\"]\n",
      "[0.03021, 0.0186, 0.01243, 0.01206, 0.01103]\n",
      "----------------------\n",
      "Any[\"data\", \"performance\", \"number\", \"set\", \"using\"]\n",
      "[0.01638, 0.01021, 0.00917, 0.00606, 0.00598]\n",
      "----------------------\n",
      "Any[\"time\", \"data\", \"neural\", \"analysis\", \"model\"]\n",
      "[0.01271, 0.01264, 0.01019, 0.00885, 0.0083]\n",
      "----------------------\n",
      "Any[\"matrix\", \"theorem\", \"sparse\", \"matrices\", \"error\"]\n",
      "[0.03241, 0.00922, 0.00794, 0.00753, 0.0075]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "TopicModels.show_topics(corpus, lda, 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
