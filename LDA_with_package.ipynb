{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Activating\u001b[22m\u001b[39m environment at `~/Documents/Thesis/Git_Main/handson_julia/TopicModels/Project.toml`\n",
      "┌ Info: Precompiling TopicModels [cfcb1801-bb54-4f1b-8249-336c042d2c46]\n",
      "└ @ Base loading.jl:1278\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "using StatsBase, CSV, DataFrames\n",
    "Pkg.activate(\"TopicModels\")\n",
    "import TopicModels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Run on Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = TopicModels.documentset_readData(\"news.txt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordPrior = TopicModels.Dirichlet(12, 0.01)\n",
    "M = 3\n",
    "alpha = [0.01 for i in 1:M];\n",
    "topicPrior = TopicModels.Dirichlet(alpha);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = TopicModels.LDA(topicPrior, wordPrior);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = TopicModels.lda_sample(corpus.documents, lda);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st topic and top 5 words along with vocab proportion\n",
    "words, proportions = TopicModels.lda_topicN(3, 4, corpus, lda);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"部隊\", \"選手\", \"時代\", \"文化\"]\n",
      "[0.39258, 0.19727, 0.19727, 0.19727]\n"
     ]
    }
   ],
   "source": [
    "println(words)\n",
    "println(proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA on NIPS papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing papers and few preprocessing steps\n",
    "papers = CSV.read(\"papers.csv\", DataFrame);\n",
    "papers_txt = papers.paper_text;\n",
    "stopwords = []\n",
    "specialchars = ['!', '”', '#', '$', '%', '&', '’', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '>', '=', '@', '?', '[', ']', '^', '_', '{', '}', '|', '~']\n",
    "open(\"stopwords.txt\") do file\n",
    "    for word in eachline(file)\n",
    "        push!(stopwords, word)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "function clean_words(docs::Array, stopwords::Array, specialchars::Array) \n",
    "    #Remove stop words, special characters, numbers, and 2_or_less char words\n",
    "    new_docs = []\n",
    "    for line in docs\n",
    "        doc = split(line)\n",
    "        temp = []\n",
    "        for word in doc\n",
    "            word = lowercase(replace.(word, specialchars => \"\"))\n",
    "            if !(word in stopwords) \n",
    "                if length(word) > 2 && tryparse(Float64, word) == nothing\n",
    "                    push!(temp, word)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        push!(new_docs, temp)\n",
    "    end\n",
    "    return new_docs\n",
    "end\n",
    "\n",
    "papers_txt = clean_words(papers_txt, stopwords, specialchars);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399311"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = TopicModels.documentset_readData(papers_txt);\n",
    "corpus.vocab_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordPrior = TopicModels.Dirichlet(corpus.vocab_count, 0.01)\n",
    "M = 30 # Number of topics\n",
    "alpha = [0.01 for i in 1:M];\n",
    "topicPrior = TopicModels.Dirichlet(alpha);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = TopicModels.LDA(topicPrior, wordPrior);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = TopicModels.lda_sample(corpus.documents, lda);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 top 10 words:\n",
      "Any[\"distribution\", \"inference\", \"sampling\", \"posterior\", \"variational\", \"bayesian\", \"log\", \"variables\", \"models\", \"distributions\"]\n",
      "Topic 2 top 10 words:\n",
      "Any[\"theorem\", \"function\", \"let\", \"bound\", \"case\", \"proof\", \"functions\", \"lemma\", \"following\", \"result\"]\n",
      "Topic 3 top 10 words:\n",
      "Any[\"label\", \"labels\", \"learning\", \"active\", \"ranking\", \"query\", \"model\", \"set\", \"queries\", \"number\"]\n",
      "Topic 4 top 10 words:\n",
      "Any[\"distribution\", \"estimation\", \"estimate\", \"probability\", \"sample\", \"information\", \"estimator\", \"density\", \"samples\", \"distributions\"]\n",
      "Topic 5 top 10 words:\n",
      "Any[\"network\", \"networks\", \"neural\", \"input\", \"learning\", \"output\", \"layer\", \"units\", \"hidden\", \"training\"]\n",
      "Topic 6 top 10 words:\n",
      "Any[\"training\", \"classification\", \"set\", \"error\", \"examples\", \"data\", \"classifier\", \"learning\", \"class\", \"test\"]\n",
      "Topic 7 top 10 words:\n",
      "Any[\"learning\", \"loss\", \"bound\", \"algorithm\", \"bounds\", \"risk\", \"distribution\", \"complexity\", \"sample\", \"algorithms\"]\n",
      "Topic 8 top 10 words:\n",
      "Any[\"model\", \"word\", \"words\", \"models\", \"topic\", \"language\", \"data\", \"topics\", \"latent\", \"document\"]\n",
      "Topic 9 top 10 words:\n",
      "Any[\"data\", \"tasks\", \"task\", \"group\", \"brain\", \"using\", \"multitask\", \"prediction\", \"functional\", \"features\"]\n",
      "Topic 10 top 10 words:\n",
      "Any[\"algorithm\", \"gradient\", \"optimization\", \"regret\", \"stochastic\", \"convergence\", \"algorithms\", \"convex\", \"problem\", \"descent\"]\n",
      "Topic 11 top 10 words:\n",
      "Any[\"time\", \"state\", \"states\", \"sequence\", \"system\", \"dynamics\", \"control\", \"model\", \"dynamic\", \"process\"]\n",
      "Topic 12 top 10 words:\n",
      "Any[\"system\", \"figure\", \"circuit\", \"analog\", \"output\", \"input\", \"chip\", \"neural\", \"current\", \"control\"]\n",
      "Topic 13 top 10 words:\n",
      "Any[\"tree\", \"node\", \"nodes\", \"trees\", \"algorithm\", \"hierarchical\", \"structure\", \"one\", \"search\", \"level\"]\n",
      "Topic 14 top 10 words:\n",
      "Any[\"model\", \"visual\", \"figure\", \"response\", \"human\", \"stimulus\", \"two\", \"responses\", \"stimuli\", \"spatial\"]\n",
      "Topic 15 top 10 words:\n",
      "Any[\"game\", \"strategy\", \"one\", \"rules\", \"games\", \"information\", \"rule\", \"player\", \"would\", \"decision\"]\n",
      "Topic 16 top 10 words:\n",
      "Any[\"model\", \"data\", \"models\", \"gaussian\", \"parameters\", \"function\", \"prior\", \"likelihood\", \"mixture\", \"bayesian\"]\n",
      "Topic 17 top 10 words:\n",
      "Any[\"kernel\", \"kernels\", \"learning\", \"function\", \"problem\", \"space\", \"functions\", \"methods\", \"linear\", \"regularization\"]\n",
      "Topic 18 top 10 words:\n",
      "Any[\"deep\", \"neural\", \"model\", \"networks\", \"training\", \"learning\", \"convolutional\", \"network\", \"models\", \"layers\"]\n",
      "Topic 19 top 10 words:\n",
      "Any[\"time\", \"number\", \"search\", \"size\", \"memory\", \"algorithm\", \"constraints\", \"set\", \"using\", \"large\"]\n",
      "Topic 20 top 10 words:\n",
      "Any[\"signal\", \"speech\", \"signals\", \"time\", \"using\", \"frequency\", \"filter\", \"source\", \"noise\", \"used\"]\n",
      "Topic 21 top 10 words:\n",
      "Any[\"image\", \"images\", \"object\", \"model\", \"objects\", \"segmentation\", \"figure\", \"using\", \"vision\", \"recognition\"]\n",
      "Topic 22 top 10 words:\n",
      "Any[\"features\", \"feature\", \"learning\", \"training\", \"classification\", \"dataset\", \"data\", \"performance\", \"method\", \"using\"]\n",
      "Topic 23 top 10 words:\n",
      "Any[\"distance\", \"points\", \"data\", \"space\", \"point\", \"local\", \"metric\", \"manifold\", \"embedding\", \"nearest\"]\n",
      "Topic 24 top 10 words:\n",
      "Any[\"algorithm\", \"clustering\", \"cluster\", \"data\", \"clusters\", \"problem\", \"set\", \"algorithms\", \"submodular\", \"number\"]\n",
      "Topic 25 top 10 words:\n",
      "Any[\"policy\", \"learning\", \"reward\", \"action\", \"state\", \"function\", \"value\", \"reinforcement\", \"actions\", \"agent\"]\n",
      "Topic 26 top 10 words:\n",
      "Any[\"time\", \"model\", \"user\", \"users\", \"data\", \"events\", \"event\", \"items\", \"process\", \"influence\"]\n",
      "Topic 27 top 10 words:\n",
      "Any[\"matrix\", \"problem\", \"sparse\", \"norm\", \"algorithm\", \"convex\", \"method\", \"rank\", \"optimization\", \"solution\"]\n",
      "Topic 28 top 10 words:\n",
      "Any[\"neurons\", \"neuron\", \"spike\", \"neural\", \"time\", \"input\", \"activity\", \"synaptic\", \"model\", \"firing\"]\n",
      "Topic 29 top 10 words:\n",
      "Any[\"graph\", \"graphs\", \"variables\", \"edge\", \"edges\", \"models\", \"model\", \"nodes\", \"graphical\", \"structure\"]\n",
      "Topic 30 top 10 words:\n",
      "Any[\"matrix\", \"data\", \"linear\", \"analysis\", \"algorithm\", \"matrices\", \"vector\", \"basis\", \"pca\", \"vectors\"]\n"
     ]
    }
   ],
   "source": [
    "top_N = 10\n",
    "for i in 1:M\n",
    "    println(\"Topic $i top $top_N words:\")\n",
    "    words, proportions = TopicModels.lda_topicN(i, top_N, corpus, lda);\n",
    "    println(words)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
